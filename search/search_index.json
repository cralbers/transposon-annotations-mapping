{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Transposon Annotations and Mapping Process","text":"<p>This website is just my notes and process for generating transposon annotations and then tracking their movement during SPUR (Summer 2022). There are 2 main parts:</p> <ol> <li>overall annotation workflow</li> <li>overall mapping workflow</li> </ol> <p>Each of these pages have subpages that outline the general steps I took for each portion of this process! Hopefully this makes sense to somebody other than me :) </p> <ul> <li>Also the github link in the top right corner links to a repo with all of the code I mention in here, as well as my edited TEUlt source code and documentation for the individual programs</li> </ul>"},{"location":"scripts/","title":"Code and Example Scripts","text":""},{"location":"scripts/#te-ult-source-code-changes","title":"TE Ult source code changes","text":"<p>these are documents describing the changes I made to the TEUlt source code, but you can also download the complete edited source code from the github link at the top right (or here)</p> <ul> <li>LTR Retriever integration into TEUlt: LTRRet_integration.md</li> <li>Other random TEUlt source code changes: other_source_changes.md</li> </ul>"},{"location":"scripts/#jupyter-notebooks","title":"Jupyter notebooks","text":"<ul> <li>TE Ult reasonaTE graphing: TEUlt_reasonaTE_graphs.ipynb</li> <li>TE Ult size filtering: TEUlt_reasonaTE_sizefilter.ipynb</li> <li>TE Ult resonaTE graphing and size filtering in one notebook (also the most recently updated version): TEUlt_reasonaTE_gff_USE_10.ipynb</li> <li>TE Ult TE mapping: TEUlt_find_unique_TEs_7.ipynb</li> </ul>"},{"location":"scripts/#example-talapas-scripts","title":"Example Talapas scripts","text":""},{"location":"scripts/#to-run-transposon-ultimate-steps","title":"To run Transposon Ultimate steps","text":"<ul> <li>TEUlt annotations: TEUlt_annotations.sh</li> <li>TEUlt pipeline: TEUlt_pipeline.sh</li> </ul>"},{"location":"scripts/#to-run-specific-programs","title":"To run specific programs","text":"<ul> <li>MUST: must_talapas.sh</li> <li>LTR Finder parallel: ltrfinder_parallel_talapas.sh</li> <li>LTR Retriever: ltrret_talapas.sh</li> </ul>"},{"location":"scripts/#programs","title":"Programs","text":"<ul> <li>SINE Finder python script: sine_finder.py</li> <li>MUST perl script: MUST_Pipe.pl</li> </ul>"},{"location":"scripts/MUST_Pipe/","title":"MUST Pipe","text":"<ul> <li>this is the perl script that you will actually use- if you know how to read perl, more power to ya</li> <li>it's called MUST_Pipe.pl in the unzipped MUST program folder, don't use any of the other ones that are called ~old.pl and whatnot</li> </ul> <pre><code>#!/usr/bin/perl -w\nuse strict;\nuse warnings;\nuse MIME::Base64;\nuse Bio::SeqIO;\nuse Bio::SearchIO;\nuse threads;\nuse threads::shared;\nmy$tline=\"\";my@tlist=();my$tempi=0;my$tempj=0;my$tempk=0;my$pline=\"\";my@plist=();my$tid=0;my%tidx=();\nmy$egDirTemp=\"tempData\";my$egScriptMUST=\"MUST\";my$egScriptPWD=\"PairWiseDistance\";my$egScriptFilter=\"filterRedundancy.new.pl\";my$egLogFilter=\"log.filterRedundancy.new.log\";\nif(system(\"echo \\\"\\\" &gt; \\\"$egLogFilter\\\"\")){die\"-Error when clearing the log file!\\n\";}my$egDirScript=$0;\n@tlist=split(/\\//,$egDirScript);\nif(@tlist==1){$egDirScript=\".\";}else{$egDirScript=~s/\\/$tlist[@tlist-1]$//g;}$|=1;\nmy$gMinTIR=8;\nmy$gMaxTIR=50;\nmy$gMinDR=2;\nmy$gMaxDR=30;\nmy$gMinMITE=100;\nmy$gMaxMITE=600;\nmy$gFixedFlanking=50;\nmy$gMutationRate=0.80;\nmy$egFileSeq=\"\";\nmy$egFileOut=\"\";\nmy$egPTNum=10;\nif((@ARGV==3)or(@ARGV==12)){}else{print\"Error in syntax!\\n\";\n&amp;efSyntax();\ndie\"-----------------------------------------------------------------------------\\n\";}$egFileSeq=$ARGV[0];$egFileOut=$ARGV[1];$egDirTemp=$ARGV[2];\nmy$egFileSize=-s$egFileSeq;\nmy$egSizeOne=int($egFileSize/$egPTNum+1.0);\nif(-d$egDirTemp){}else{if(system(\"mkdir -p \\\"$egDirTemp\\\"\")){die\"-Error when creating the temporary directory!\\n\";}}if(@ARGV==12){$egPTNum=$ARGV[3];$gMinTIR=$ARGV[4];$gMaxTIR=$ARGV[5];$gMinDR=$ARGV[6];$gMaxDR=$ARGV[7];$gMinMITE=$ARGV[8];$gMaxMITE=$ARGV[9];$gFixedFlanking=$ARGV[10];$gMutationRate=$ARGV[11];}my$egCutOffIdent=$gMutationRate;\nmy%mMITE2ID=();\nmy@mID=();\nmy@mGID=();\nmy@mStart=();\nmy@mEnd=();\nmy@mStrand=();\nmy@mLength=();\nmy@mDR=();\nmy@mDRIdent=();\nmy@mDRLeft=();\nmy@mDRRight=();\nmy@mTIR=();\nmy@mTIRIdent=();\nmy@mTIRLeft=();\nmy@mTIRRight=();\nmy@mDRAT=();\nmy@mTIRAT=();\nmy@mMITEAT=();\nmy@mFDRAT=();\nmy@mPreSite=();\nmy@mPostSite=();\nmy@mMITE=();\nmy@mCopyNum=();\nmy@mCopies=();\nmy@mTotalScore=();\nmy@mFlag=();\nmy$mNum=0;\nmy%mData=();\nmy%egExistCopy=();\nmy$egCutOffCopyScore=10;\nmy$egLineLength=60;\nmy$egTimeOld=`date +%s`;\nmy$egTimeNew=`date +%s`;\nmy$egSeq=\"\";\nmy$egID=\"\";\nmy$lFile=\"\";\nmy$lFSeq=\"\";\nmy$lCmdLine=\"\";\nmy$lFileDat=\"\";\nmy$lFileTIR=\"\";\nmy$lFileEdge=\"\";\n$egTimeOld=`date +%s`;\nmy$egTID=1;\nmy$egFileSub=\"$egDirTemp/sub-genome.$egTID.fasta\";\nmy$egSizeNow=$egSizeOne;\nprint\"Spliting the genome into $egPTNum sub-genomes ... \";\nopen(efO,\"&gt;$egFileSub\")or die\"Error:$egTID!\\n\";\nmy$egSeqObj=new Bio::SeqIO(-file=&gt;\"$egFileSeq\",-format=&gt;\"fasta\");\nwhile(my$egSeqO=$egSeqObj-&gt;next_seq){$tline=$egSeqO-&gt;seq;$egSeq=\"\\U$tline\\E\";$egID=$egSeqO-&gt;id;\nmy$tStartPos=0;\nmy$tLength=length($egSeq);\nwhile(1){if($egTID&gt;=$egPTNum){print efO\"&gt;$tStartPos;;$egID\\n\".substr($egSeq,$tStartPos,$tLength-$tStartPos).\"\\n\";\n$egSizeNow=0;$tStartPos=0;\nlast;}elsif($egSizeNow&gt;=$tLength-$tStartPos){print efO\"&gt;$tStartPos;;$egID\\n\".substr($egSeq,$tStartPos,$tLength-$tStartPos).\"\\n\";\n$egSizeNow-=$tLength-$tStartPos;\n$tStartPos=0;\nlast;}else{print efO\"&gt;$tStartPos;;$egID\\n\".substr($egSeq,$tStartPos,$egSizeNow).\"\\n\";\n$tStartPos+=$egSizeNow-2*($gFixedFlanking+$gMaxDR+$gMaxMITE+$gMaxDR+$gFixedFlanking);\nclose(efO);\n$egTID++;\nopen(efO,\"&gt;$egDirTemp/sub-genome.$egTID.fasta\")or die\"EEE:$egTID!\\n\";\n$egSizeNow=$egSizeOne;}}}$egTimeNew=`date +%s`;\nclose(efO);\nprint\" [SubFiles:$egTID] [done] [Elapsed time: \".($egTimeNew-$egTimeOld).\" seconds]\\n\";\nprint\"Scanning the nucleotide sequences for potential MITEs ... \";\n$egTimeOld=`date +%s`;\nmy@egPTID=();\nmy$egSleepTime=5;\nfor($tempi=1;$tempi&lt;=$egPTNum;$tempi++){my$tPID=threads-&gt;new(\\&amp;efPTMUST,$tempi,\"$egDirTemp/sub-genome.$tempi.fasta\");\n$egPTID[$tempi]=$tPID;}$egTimeNew=`date +%s`;\n%tidx=();\nwhile(1){for($tempi=1;$tempi&lt;=$egPTNum;$tempi++){$tid=$egPTID[$tempi];\nif(($tid-&gt;is_joinable())and(!(defined$tidx{\"$tempi\"}))){$tid-&gt;join();$tidx{\"$tempi\"}=1;}}if((scalar keys%tidx)==$egPTNum){last;}sleep($egSleepTime);}$egTimeNew=`date +%s`;\nprint\"Total calculation time elapsed: \".($egTimeNew-$egTimeOld).\" seconds.\\n\";\nprint\"Loading the annotation data ... \";\n$egTimeOld=`date +%s`;\n$tempj=0;$tempk=0;\nfor($tempi=1;$tempi&lt;=$egPTNum;$tempi++){$tempj=&amp;efLoadMUST(\"$egDirTemp/$tempi.temp_seq.dat\");\n$tempk+=$tempj;}$egTimeNew=`date +%s`;\nprint\" [RawMITEs:$tempk] [done] [Time:\".($egTimeNew-$egTimeOld).\" seconds]\\n\";\nmy$egCmdLine=\"\";\nprint\"Removing redundancy in the predicted MITEs ... \";\nmy@mSortID=();\nmy@mNewID=();\nfor($tempi=0;$tempi&lt;$mNum;$tempi++){$mSortID[$tempi]=$tempi;}@mNewID=sort{$mGID[$a]cmp$mGID[$b]or$mStart[$a]&lt;=&gt;$mStart[$b]or$mEnd[$a]&lt;=&gt;$mEnd[$b]}@mSortID;\n$tempk=0;\nfor($tempi=0;$tempi&lt;@mNewID-1;$tempi++){my($newA,$newB)=($mNewID[$tempi],$mNewID[$tempi+1]);\n$tempj=1;\nwhile(($mFlag[$newA]==1)and($mEnd[$newA]&gt;=$mStart[$newB])){if($mFlag[$newB]==0){$tempj++;$newB=$mNewID[$tempi+$tempj];}elsif($mTotalScore[$newA]&gt;=$mTotalScore[$newB]){$mFlag[$newB]=0;\n$tempk++;\n$tempj++;\n$newB=$mNewID[$tempi+$tempj];}else{$mFlag[$newA]=0;\n$tempk++;}}}print\" [RuleBasedRemoving:$tempk]\";\n$tempj=0;\nfor($tempi=0;$tempi&lt;$mNum;$tempi++){if($mFlag[$tempi]==1){$tempj++;}}$egTimeNew=`date +%s`;\nprint\" [MITE:$tempj] [done] [Time:\".($egTimeNew-$egTimeOld).\" seconds]\\n\";\n$egTimeOld=$egTimeNew;\nmy$egCutOffCopyNum=3;\nmy$egCutOffEValue=1e-20;\nprint\"Clustering ... \";\nmy@mClusterID=();\nmy%mC2IDs=();\nfor($tempi=0;$tempi&lt;$mNum;$tempi++){$mClusterID[$tempi]=-1;}my$mCluster=0;\nmy$mMITEWithCluster=0;\nmy%tInCluster=();\nmy$tFirstMITE=-1;\nmy@tInClusterList=();\nmy@tNeighborList=();\nmy$egClusterMode=1;\nmy$egFileMITESeq=\"$egDirTemp/temp-mite-seq.fasta\";\nopen(efO,\"&gt;$egFileMITESeq\")or die\"E!\\n\";\nfor($tempi=0;$tempi&lt;$mNum;$tempi++){print efO\"&gt;$tempi\\n$mMITE[$tempi]\\n\";}close(efO);\nsystem(\"formatdb -p F -i \\\"$egFileMITESeq\\\"\");\nsystem(\"megablast -d \\\"$egFileMITESeq\\\" -i \\\"$egFileMITESeq\\\" -F F -e $egCutOffEValue -m 9 -o \\\"$egDirTemp/temp-mite-seq.all-vs-all.megablast.txt\\\" 2&gt;&amp;1 1&gt;&gt;\\\"$egDirTemp/temp-mite-seq.all-vs-all.megablast.log\\\" \");\nprint\" [BLAST]\";\nmy%idxIdent=();\nmy%idxSameStrand=();\nmy@mCC=();\nmy@mFF=();\nopen(efI,\"$egDirTemp/temp-mite-seq.all-vs-all.megablast.txt\")or die\"EE!\\n---[$egDirTemp/temp-mite-seq.all-vs-all.megablast.txt]---\\n\";\nwhile(&lt;efI&gt;){$tline=$_;$tline=~s/[\\r\\n]//g;@tlist=split(/\\t/,$tline);\nif($tline=~/^#/){}elsif(@tlist&gt;=12){if($tlist[0]&lt;$tlist[1]){$idxIdent{$tlist[0].$tlist[1]}=$tlist[2]*$tlist[3]/100;\nif($tlist[8]&lt;=$tlist[9]){$idxSameStrand{$tlist[0].$tlist[1]}=1;}}elsif($tlist[0]&gt;$tlist[1]){$idxIdent{$tlist[1].$tlist[0]}=$tlist[2]*$tlist[3]/100;\nif($tlist[8]&lt;=$tlist[9]){$idxSameStrand{$tlist[1].$tlist[0]}=1;}}}}close(efI);\nfor($tempi=0;$tempi&lt;$mNum;$tempi++){$mCC[$tempi]=\"$tempi\";\n$mFF[$tempi]=0;\n$mClusterID[$tempi]=0;}for($tempi=0;$tempi&lt;$mNum;$tempi++){for($tempj=$tempi+1;$tempj&lt;$mNum;$tempj++){$tid=$idxIdent{$tempi.$tempj};\nif(defined$tid){if(($tid&gt;=$egCutOffIdent*$mLength[$tempi])and($tid&gt;=$egCutOffIdent*$mLength[$tempj])){$mCC[$tempi].=\" $tempj\";\n$mCC[$tempj].=\" $tempi\";}}}}my@mCFlag=();\nmy$egClusterNumber=1;\nfor($tempi=0;$tempi&lt;$mNum;$tempi++){my$kCID=$egClusterNumber;\n$mCC[$tempi]=~s/^ +//g;\n@tlist=split(/ /,$mCC[$tempi]);\nif((scalar@tlist)&lt;$egCutOffCopyNum){$mCFlag[$tempi]=0;}else{$mCFlag[$tempi]=1;\nfor($tempj=0;$tempj&lt;@tlist;$tempj++){if(($mClusterID[$tlist[$tempj]]&gt;0)and($mClusterID[$tlist[$tempj]]&lt;$kCID)){$kCID=$mClusterID[$tempj];}}for($tempj=0;$tempj&lt;@tlist;$tempj++){if($mClusterID[$tlist[$tempj]]==0){$mClusterID[$tlist[$tempj]]=$kCID;}}if($mClusterID[$tempi]==0){$mClusterID[$tempi]=$kCID;}if($kCID==$egClusterNumber){$egClusterNumber++;}}}$mCluster=$egClusterNumber-1;\nfor($tempi=0;$tempi&lt;$mNum;$tempi++){if($mCFlag[$tempi]==1){$tid=$mC2IDs{\"$mClusterID[$tempi]\"};\nif(defined$tid){$tid.=\";$tempi\";}else{$tid=\"$tempi\";}$mC2IDs{\"$mClusterID[$tempi]\"}=$tid;}}$egTimeNew=`date +%s`;\nprint\" [done] [ClusterNum:$mCluster] [Time:\".($egTimeNew-$egTimeOld).\" seconds]\\n\";\n$egTimeOld=$egTimeNew;\nprint\"Deciding the strand information of each valid MITE ... \";\nfor($tempi=0;$tempi&lt;$mNum;$tempi++){if(($mFlag[$tempi]==1)and($mCFlag[$tempi]==1)and($mStrand[$tempi]eq\"\")){$mStrand[$tempi]=\"+\";\nfor($tempj=$tempi+1;$tempj&lt;$mNum;$tempj++){if(($mFlag[$tempj]==1)and($mCFlag[$tempj]==1)and($mClusterID[$tempj]==$mClusterID[$tempi])){if(defined$idxSameStrand{$tempi.$tempj}){$mStrand[$tempj]=\"+\";}else{$mStrand[$tempj]=\"-\";}}}}}$egTimeNew=`date +%s`;\nprint\" [done] [Time:\".($egTimeNew-$egTimeOld).\" seconds]\\n\";\n$egTimeOld=$egTimeNew;\nprint\"Saving the data ... \";\n$tempj=0;\nopen(efOut,\"&gt;$egFileOut\\.before_filter\")or die\"Error when saving the predicted MITEs!\\n\";\nprint efOut\"#GID    ID  Cluster Start   End Strand  Length  DR  DRIdent DRLeft  DRRight TIR TIRIdent    TIRLeft TIRRight    DRAT    TIRAT   MITEAT  FDRAT   PreSite PostSite    MITE    TotalScore\\n\";\nfor($tempi=0;$tempi&lt;$mNum;$tempi++){if(($mCFlag[$tempi]==1)and($mClusterID[$tempi]&gt;0)and($mFlag[$tempi]==1)){$mCopies[$tempi]=~s/\\s/,/g;\nprint efOut\"$mGID[$tempi]   $mID[$tempi]    $mClusterID[$tempi] $mStart[$tempi] $mEnd[$tempi]   $mStrand[$tempi]    $mLength[$tempi]    $mDR[$tempi]    $mDRIdent[$tempi]   $mDRLeft[$tempi]    $mDRRight[$tempi]   $mTIR[$tempi]   $mTIRIdent[$tempi]  $mTIRLeft[$tempi]   $mTIRRight[$tempi]  $mDRAT[$tempi]  $mTIRAT[$tempi] $mMITEAT[$tempi]    $mFDRAT[$tempi] $mPreSite[$tempi]   $mPostSite[$tempi]  $mMITE[$tempi]  $mTotalScore[$tempi]\\n\";\n$tempj++;}}close(efOut);\nif(system(\"$egDirScript/filterCopyNum.pl \\\"$egFileOut.before_filter\\\" \\\"$egFileOut.filter-1\\\" $egCutOffCopyNum &gt;/dev/null\")or system(\"$egDirScript/filterSegDup-2.pl \\\"$egFileOut.filter-1\\\" \\\"$egFileOut\\\" 4 3 &gt;/dev/null\")){die\"-Error when filtering!\\n\";}$egTimeNew=`date +%s`;\nprint\" [done] [ValidMITENum:$tempj] [Time:\".($egTimeNew-$egTimeOld).\" seconds]\\n\";\n$egTimeOld=$egTimeNew;\nprint\"Screening for all the MITE copies ... \";\nopen(efI,\"$egFileOut\")or die\"Q!\\n\";\nopen(efO,\"&gt;$egFileOut.before_expansion\")or die\"!!\\n\";\n$tempi=0;\nwhile(&lt;efI&gt;){$tline=$_;$tline=~s/[\\r\\n]//g;@tlist=split(/\\t/,$tline);\nif($tline=~/^#/){print efO\"$tline\\n\";}elsif(@tlist&gt;=23){$tlist[1]=$tempi;\n$tlist[22]=&amp;efEScore($tlist[7],$tlist[11],$tlist[8],$tlist[12]);\nprint efO\"\".join(\"\\t\",@tlist).\"\\n\";\n$tempi++;}}close(efO);\nclose(efI);\nprint\" [BackupMITEs:$tempi]\";\nmy$tFileTemp=\"$egDirTemp/temp-templates.fasta\";\nmy@tGID=();\nmy@tCluster=();\nmy@tMITEID=();\nmy@tS=();\nmy@tE=();\nmy@tStrand=();\nmy@tDR=();\nmy@tTIR=();\nmy@tDRIdent=();\nmy@tTIRIdent=();\nmy@tEScore=();\nmy@tMITESeq=();\nmy$tN=0;\nmy$tMITECopy=0;\n$tempk=0;\nopen(efI,\"$egFileOut.before_expansion\")or die\"E:TemplateGeneration!\\n\";\nopen(efO,\"&gt;$tFileTemp\")or die\"E:SaveTemplate!\\n\";\nwhile(&lt;efI&gt;){$tline=$_;$tline=~s/[\\r\\n]//g;@tlist=split(/\\t/,$tline);\nif($tline=~/^#/){;}elsif(@tlist&gt;=23){print efO\"&gt;MITE;;$tlist[1];;$tlist[2];;$tlist[7];;$tlist[8];;$tlist[11];;$tlist[12]\\n$tlist[21]\\n\";\n$tGID[$tN]=$tlist[0];$tMITEID[$tN]=$tlist[1];$tCluster[$tN]=$tlist[2];$tS[$tN]=$tlist[3];$tE[$tN]=$tlist[4];$tStrand[$tN]=$tlist[5];\n$tDR[$tN]=$tlist[7];$tDRIdent[$tN]=$tlist[8];$tTIR[$tN]=$tlist[11];$tTIRIdent[$tN]=$tlist[12];\n$tEScore[$tN]=&amp;efEScore($tDR[$tN],$tTIR[$tN],$tDRIdent[$tN],$tTIRIdent[$tN]);$tMITESeq[$tN]=$tlist[21];\n$tempk++;$tN++;}}close(efO);\nclose(efI);\nprint\" [Templates:$tempk]\";\n$tMITECopy=$tN;\nmy$tFileSeq=\"$egDirTemp/temp-genome-seq.fasta\";\nmy$tFileBLAT=\"$egDirTemp/temp-genome-seq.blat-psl.txt\";\nif(system(\"cp \\\"$egFileSeq\\\" \\\"$tFileSeq\\\"\")or system(\"formatdb -p F -i \\\"$tFileSeq\\\"\")or system(\"blat \\\"$tFileSeq\\\" \\\"$tFileTemp\\\" -minIdentity=95 -minScore=100 \\\"$tFileBLAT\\\" 2&gt;&amp;1 1&gt;&gt;\\\"$egDirTemp/temp-genome-seq.blat.log\\\" \")){die\"-Error when mapping!\\n\";}print\" [BLAT]\";\nmy@pGID=();\nmy@pS=();\nmy@pE=();\nmy@pStrand=();\nmy@pMID=();\nmy@pMCluster=();\nmy@pMDR=();\nmy@pMDRIdent=();\nmy@pMTIR=();\nmy@pMTIRIdent=();\nmy@pMBitScore=();\nmy$pN=0;\nopen(efI,\"$tFileBLAT\")or die\"Error!\\n\";\nwhile(&lt;efI&gt;){$tline=$_;$tline=~s/[\\r\\n]//g;@tlist=split(/\\t/,$tline);\nif($tline=~/^#/){}elsif(($tline=~/^\\d+/)and(@tlist&gt;=12)){my$tstrand=\"+\";\n$tstrand=$tlist[8];\nmy($tmid,$tcluster,$tmdr,$tmdrident,$ttir,$ttirident)=(-1,-1,0,0,0,0);\nif($tlist[9]=~/^MITE;;(\\d+);;(\\d+);;(\\d+);;([\\d\\.]+);;(\\d+);;([\\d\\.]+)/){($tmid,$tcluster,$tmdr,$tmdrident,$ttir,$ttirident)=($1,$2,$3,$4,$5,$6);}$tid=-1;\nfor($tempi=0;$tempi&lt;$tN;$tempi++){if(($tGID[$tempi]eq$tlist[13])and(&amp;efIsOverlap($tS[$tempi],$tE[$tempi],$tlist[15],$tlist[16])==1)){$tid=-2;last;}}if($tid==-1){for($tempi=0;$tempi&lt;$pN;$tempi++){if(($pGID[$tempi]eq$tlist[13])and(&amp;efIsOverlap($pS[$tempi],$pE[$tempi],$tlist[15],$tlist[16])==1)){$tid=$tempi;last;}}if($tid!=-1){if($pMBitScore[$tid]&lt;$tlist[0]){$pGID[$tid]=$tlist[13];$pS[$tid]=$tlist[15];$pE[$tid]=$tlist[16];$pStrand[$tid]=$tstrand;\n$pMID[$tid]=$tmid;$pMCluster[$tid]=$tcluster;$pMDR[$tid]=$tmdr;$pMDRIdent[$tid]=$tmdrident;$pMTIR[$tid]=$ttir;$pMTIRIdent[$tid]=$ttirident;\n$pMBitScore[$tid]=$tlist[0];}}else{$tid=$pN;\n$pGID[$tid]=$tlist[13];$pS[$tid]=$tlist[15];$pE[$tid]=$tlist[16];$pStrand[$tid]=$tstrand;\n$pMID[$tid]=$tmid;$pMCluster[$tid]=$tcluster;$pMDR[$tid]=$tmdr;$pMDRIdent[$tid]=$tmdrident;$pMTIR[$tid]=$ttir;$pMTIRIdent[$tid]=$ttirident;\n$pMBitScore[$tid]=$tlist[0];\n$pN++;}}}}close(efI);\nprint\" [OtherCopy:$pN]\";\nmy@pSeqL=();\nmy@pSeqM=();\nmy@pSeqR=();\nmy%pGID2ID=();\nif($pN==0){goto labelNoExpanding;}for($tempi=0;$tempi&lt;$pN;$tempi++){$tid=$pGID2ID{\"$pGID[$tempi]\"};\nif(defined$tid){$tid.=\";$tempi\";}else{$tid=\"$tempi\";}$pGID2ID{\"$pGID[$tempi]\"}=$tid;}$egSeqObj=new Bio::SeqIO(-file=&gt;\"$egFileSeq\",-format=&gt;\"fasta\");\nwhile(my$egSeqO=$egSeqObj-&gt;next_seq){my($ppID,$ppSeq)=($egSeqO-&gt;id,$egSeqO-&gt;seq);\n$tline=$pGID2ID{\"$ppID\"};\nif(defined$tline){@tlist=split(/;/,$tline);\nfor($tempj=0;$tempj&lt;@tlist;$tempj++){$tid=$tlist[$tempj];\n$pSeqL[$tid]=substr($ppSeq,$pS[$tid]-1-$gFixedFlanking,$gFixedFlanking);\n$pSeqM[$tid]=substr($ppSeq,$pS[$tid],abs($pE[$tid]-$pS[$tid])+1);\nif($pStrand[$tid]ne\"+\"){$pSeqM[$tid]=&amp;efDNA_RC($pSeqM[$tid]);}$pSeqR[$tid]=substr($ppSeq,$pE[$tid]-1+1,$gFixedFlanking);}}}if(system(\"cp \\\"$egFileOut.before_expansion\\\" \\\"$egFileOut.be-filter1\\\"\")){die\"-Error!\\n\";}open(efO,\"&gt;&gt;$egFileOut.be-filter1\")or die\"E:Expansion!\\n\";\n$tempk=$tN;\nfor($tempi=0;$tempi&lt;$pN;$tempi++){$tempk++;\nprint efO\"$pGID[$tempi] $tempk  $pMCluster[$tempi]  $pS[$tempi] $pE[$tempi] $pStrand[$tempi]    \".(abs($pE[$tempi]-$pS[$tempi])+1).\"    $mDR[$tempi]    0           $pMTIR[$tempi]  0           0   0   0   0   \".($pSeqL[$tempi].$pSeqR[$tempi]).\" \".($pSeqL[$tempi].$pSeqR[$tempi]).\" \".$pSeqM[$tempi].\"  0\\n\";}close(efO);\nprint\" [AllCopySaved:$tempk]\";\nif(system(\"\\\"$egDirScript/refineBoundary.pl\\\" \\\"$egDirTemp\\\" $gMutationRate \\\"$tFileSeq\\\" \\\"$egFileOut.be-filter1\\\" \\\"$egFileOut.be-filter2\\\" 2&gt;/dev/null 1&gt;/dev/null\")){print\"\\\"$egDirScript/refineBoundary.pl\\\" \\\"$egDirTemp\\\" $gMutationRate \\\"$tFileSeq\\\" \\\"$egFileOut.be-filter1\\\" \\\"$egFileOut.be-filter2\\\"\\n\";\ndie\"-Error when refineBoundary!\\n\";}print\" [Boundary Refined]\";\nlabelNoExpanding:\nmy($tF,$tP)=(0,0);\nif($pN==0){open(efI,\"$egFileOut.before_expansion\")or die\"E!\\n\";}else{open(efI,\"$egFileOut.be-filter2\")or die\"E!\\n\";}open(efO,\"&gt;$egFileOut\")or die\"Q!\\n\";\nwhile(&lt;efI&gt;){$tline=$_;$tline=~s/[\\r\\n]//g;@tlist=split(/\\t/,$tline);\nif($tline=~/^#/){print efO\"$tline   Copy status\\n\";}elsif(@tlist&gt;=23){$tlist[22]=&amp;efEScore($tlist[7],$tlist[11],$tlist[8],$tlist[12]);\n$tlist[23]=\"\";\nif(($tlist[8]&gt;=$gMutationRate)and($tlist[12]&gt;=$gMutationRate)){$tlist[23]=\"Full Copy\";$tF++;}else{$tlist[23]=\"Partial Copy\";$tlist[7]=0;$tlist[8]=0;$tlist[9]=\"\";$tlist[10]=\"\";$tlist[11]=0;$tlist[12]=0;$tlist[13]=\"\";$tlist[14]=\"\";$tlist[15]=0;$tlist[16]=0;$tP++;}print efO\"\".join(\"\\t\",@tlist).\"\\n\";}}close(efO);\nclose(efI);\nprint\" [Full:$tF] [Partial:$tP]\";\nprint\" [done]\\n\";\nif(system(\"rm -rf \\\"$egDirTemp\\\"\")or system(\"rm -rf \\\"$egFileOut.before_filter\\\"\")or system(\"rm -rf \\\"$egFileOut.filter-1\\\"\")or system(\"rm -rf *.log\")or system(\"rm -rf \\\"$egFileOut.before_expansion\\\"\")or system(\"rm -rf \\\"$egFileOut.be-filter1\\\"\")or system(\"rm -rf \\\"$egFileOut.be-filter2\\\"\")){print\"---Error when removing the temporary files!\\n\";}my$qMITENum=0;\nmy$qClusterNum=0;\n%tidx=();\nopen(efI,\"$egFileOut\")or die\"E!\\n\";\nwhile(&lt;efI&gt;){$tline=$_;$tline=~s/[\\r\\n]//g;@tlist=split(/\\t/,$tline);\nif($tline=~/^#/){}elsif(@tlist&gt;=5){$qMITENum++;\n$tidx{\"$tlist[2]\"}=1;}}$qClusterNum=scalar keys%tidx;\nclose(efI);\nprint\"There are $qMITENum MITEs detected in $qClusterNum clusters.\\n\";\n$|=0;\nsub efEScore{my($adDR,$adTIR,$adIdentDR,$adIdentTIR)=@_;\nmy$adWeightIdent=20;\nmy$adWeightDR=2;\nmy$adEScore=$adIdentDR*$adDR*$adWeightDR+$adIdentTIR*$adTIR;\nreturn$adEScore;}sub efLoadMUST{my($tFileDat)=@_;\n%mData=();\nmy$tStartID=$mNum;\nmy$tNowNum=0;\nopen(tIn,\"$tFileDat\")or die\"Error when loading the Dat!\\n\";\nwhile(&lt;tIn&gt;){$tline=$_;\n$tline=~s/[\\r\\n]//g;\nmy($ppp,$qqq)=(\"\",\"\");\nif($tline=~/^\\/\\/$/){$egID=$mData{\"GID\"};\n$mData{\"SEQID\"}=$egID;\nmy@ttlist=();\nmy$tNowID=&amp;efValidString($mData{\"ID\"});\nif($tNowID=~/^\\d+$/){$mMITE2ID{\"$egID $tNowID\"}=$mNum;\n$mID[$mNum]=&amp;efValidString($tNowID);\n$mGID[$mNum]=&amp;efValidString($egID);\n($ppp,$qqq)=split(/;;/,$mGID[$mNum],2);\nif(!(defined$qqq)){$qqq=$ppp;$ppp=0;}$mGID[$mNum]=$qqq;\n@ttlist=split(/-/,&amp;efValidString($mData{\"POSITION\"}),2);\n$mStart[$mNum]=$ppp+&amp;efValidString($ttlist[0]);\n$mEnd[$mNum]=$ppp+&amp;efValidString($ttlist[1]);\nif(!(defined$egExistCopy{\"$mGID[$mNum]|$mStart[$mNum]-$mEnd[$mNum]\"})){$mStrand[$mNum]=\"\";\n$mLength[$mNum]=abs($mEnd[$mNum]-$mStart[$mNum])+1;\n$mDR[$mNum]=&amp;efValidString($mData{\"DR\"});\n$mDRIdent[$mNum]=&amp;efValidString($mData{\"DRIDENT\"});\n$mDRLeft[$mNum]=&amp;efValidString($mData{\"DRLEFT\"});\n$mDRRight[$mNum]=&amp;efValidString($mData{\"DRRIGHT\"});\n$mTIR[$mNum]=&amp;efValidString($mData{\"TIR\"});\n$mTIRIdent[$mNum]=&amp;efValidString($mData{\"TIRIDENT\"});\n$mTIRLeft[$mNum]=&amp;efValidString($mData{\"TIRLEFT\"});\n$mTIRRight[$mNum]=&amp;efValidString($mData{\"TIRRIGHT\"});\n$mDRAT[$mNum]=&amp;efValidString($mData{\"DRAT\"});\n$mTIRAT[$mNum]=&amp;efValidString($mData{\"TIRAT\"});\n$mMITEAT[$mNum]=&amp;efValidString($mData{\"MITEAT\"});\n$mFDRAT[$mNum]=&amp;efValidString($mData{\"FDRAT\"});\n$mPreSite[$mNum]=&amp;efValidString($mData{\"PRESITE\"});\n$mPostSite[$mNum]=&amp;efValidString($mData{\"POSTSITE\"});\n$mMITE[$mNum]=&amp;efValidString($mData{\"MITE\"});\n$mTotalScore[$mNum]=&amp;efEScore($mDR[$mNum],$mTIR[$mNum],$mDRIdent[$mNum],$mTIRIdent[$mNum]);\n$mCopyNum[$mNum]=1;\n$mCopies[$mNum]=\"$mNum\";\n$mFlag[$mNum]=1;\n$egExistCopy{\"$mGID[$mNum]|$mStart[$mNum]-$mEnd[$mNum]\"}=1;\n$tNowNum++;\n$mNum++;}}}elsif($tline=~/^([a-zA-Z]+)\\t(.*)$/){my$tID=&amp;efValidString($1);\nmy$tDat=&amp;efValidString($2);\nif(($tID ne\"\")and($tDat ne\"\")){$mData{\"$tID\"}=$tDat;}}}close(tIn);\nreturn$tNowNum;}sub efPTMUST{my($tmPID,$tmFileSeq)=@_;\nmy$tmgTimeOld=`date +%s`;\nmy$tmSeqObj=new Bio::SeqIO(-file=&gt;\"$tmFileSeq\",-format=&gt;\"fasta\");\nwhile(my$tmSeqO=$tmSeqObj-&gt;next_seq){my$tmTimeOld=`date +%s`;\nmy$ttmSeq=$tmSeqO-&gt;seq;my$tmSeq=\"\\U$ttmSeq\\E\";my$tmID=$tmSeqO-&gt;id;\nmy$tmFile=\"\";my$tmFSeq=\"\";my$tmCmdLine=\"\";my$tmFileDat=\"\";my$tmFileTIR=\"\";\n$tmFSeq=&amp;efFormatSeq($tmSeq,$egLineLength,1);\n$tmFSeq=~s/ +//g;\n$tmFile=\"$egDirTemp/$tmPID.temp_seq.raw\";\nopen(tmOut,\"&gt;$tmFile\")or die\"Error when saving the temporary sequence!\\n\";\nprint tmOut\"$tmFSeq\\n\";\nclose(tmOut);\n$tmFileDat=\"$egDirTemp/$tmPID.temp_seq.dat\";$tmFileTIR=\"$egDirTemp/$tmPID.temp_tir.dat\";\n$tmCmdLine=\"\\\"$egDirScript\\/$egScriptMUST\\\" \\\"$tmFile\\\" \\\"$tmID\\\" \\\"$tmFileDat.before_filter\\\" \\\"$tmFileTIR\\\" $gMinTIR $gMaxTIR $gMinDR $gMaxDR $gMinMITE $gMaxMITE $gFixedFlanking $gMutationRate\";\nif(system(\"$tmCmdLine &gt;/dev/null\")){die\"-Error occurred when running the script \\\"$egDirScript\\/$egScriptMUST\\\"!\\n\";}$tmCmdLine=\"\\\"$egDirScript/$egScriptFilter\\\" \\\"$tmFileDat.before_filter\\\" \\\"$tmFileDat\\\"\";\nif(system(\"$tmCmdLine 2&gt;/dev/null 1&gt;/dev/null\")){die\"-Error occurred when running the script \\\"$egDirScript\\/$egScriptFilter\\\"!\\n\";}}my$tmgTimeNew=`date +%s`;}sub efValidString{my($tStr)=@_;\nif((defined$tStr)and($tStr ne\"\")){return$tStr;}else{return\"\";}}sub efSyntax{my$egSyntax=decode_base64(\"TUlURSBVbmNvdmVyaW5nIFN5c1RlbSAgICB2ZXJzaW9uIDIuNC4wMDEKLS0tLS0tLS0tLS0tLS0t\nLS0tLS0tKGMpIEZlbmdmZW5nIFpob3UgKEZlbmdmZW5nWmhvdUBnbWFpbC5jb20pIDIwMTMtMTIt\nMjgKLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0t\nLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tCi4vTVVTVF9QaXBlLnBsIDxpbnB1dC5mYXN0YT4g\nPG91dHB1dC5NSVRFLmRhdD4gPERpclRlbXA+IFtvcHRpb25zXQpOb3RlOgpJZiBhbnkgb3B0aW9u\ncyBhcmUgcHJvdmlkZWQsIHRoZSB1c2VyIGhhdmUgdG8gaW5wdXQgdGhlIHZhbHVlcyBmb3IgYWxs\nIHRoZSBvcHRpb25zLgpPcHRpb24gbGlzdDoKLTxUaHJlYWRfTnVtPiAgICAgICAgICAgICBbMTBd\nCi08TUlOX1RJUl9sZW5ndGg+ICAgICAgICAgWzhdCi08TUFYX1RJUl9sZW5ndGg+ICAgICAgICAg\nWzUwXQotPE1JTl9EUl9sZW5ndGg+ICAgICAgICAgIFsyXQotPE1BWF9EUl9sZW5ndGg+ICAgICAg\nICAgIFszMF0KLTxNSU5fTUlURV9sZW5ndGg+ICAgICAgICBbMTAwXQotPE1BWF9NSVRFX2xlbmd0\naD4gICAgICAgIFs2MDBdCi08RklYRURfRkxBTktJTkdfbGVuZ3RoPiAgWzUwXQotPE11dGF0aW9u\nX1JhdGU+ICAgICAgICAgIFswLjgwXQotLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0t\nLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLQo=\"\n);\nprint$egSyntax;}sub efFormatSeq{my($fSeq,$tBlock,$tNumber)=@_;\nmy$tPos=0;\nmy$tRSeq=\"\";\nwhile(1){my$tStart=$tBlock*$tPos;\nmy$tEnd=$tBlock*($tPos+1)-1;\nif($tStart&gt;=length($fSeq)){last;}if($tEnd&gt;=length($fSeq)){$tEnd=length($fSeq)-1;}$tRSeq=$tRSeq.substr($fSeq,$tStart,abs($tEnd-$tStart)+1).\" \";\nif(($tPos&gt;=0)and($tPos%$tNumber==0)){$tRSeq=$tRSeq.\"\\n     \";}$tPos++;}$tRSeq=~s/^ +//g;\n$tRSeq=~s/ +$//g;\n$tRSeq=\"     \".$tRSeq;\nreturn$tRSeq;}sub efIsOverlap{my($s1,$e1,$s2,$e2)=@_;\nmy$t=0;\nif($s1&gt;$e1){$t=$s1;\n$s1=$e1;\n$e1=$t;}if($s2&gt;$e2){$t=$s2;\n$s2=$e2;\n$e2=$t;}if((($s2&gt;=$s1)and($s2&lt;=$e1))or(($s1&gt;=$s2)and($s1&lt;=$e2))){return 1;}else{return 0;}}sub efIsSameStrand{my($iSeq1,$iSeq2)=@_;\nif((length($iSeq1)&gt;0)and(length($iSeq2)&gt;0)){my$iF1=\"$egDirTemp/seq1.fasta\";\nopen(iO,\"&gt;$iF1\")or die\"Error when saving sequence 1\\n\";\nprint iO\"&gt;Query\\n$iSeq1\\n\";\nclose(iO);\nmy$iF2=\"$egDirTemp/seq2.fasta\";\nopen(iO,\"&gt;$iF2\")or die\"Error when saving sequence 2\\n\";\nprint iO\"&gt;DB\\n$iSeq2\\n\";\nclose(iO);\nmy$iFO=\"$egDirTemp/seq.bl2seq.dat\";\nmy$iCmdLine=\"bl2seq -p blastn -i \\\"$iF1\\\" -j \\\"$iF2\\\" -o $iFO\";\nif(system($iCmdLine)){print\"-Error when running bl2seq!\\n\";\nreturn-1;}else{my$iSearchIO=new Bio::SearchIO(-file=&gt;\"$iFO\",-format=&gt;\"blast\");\nmy$iFlag=1;\nwhile(my$iResult=$iSearchIO-&gt;next_result){my$iNameQ=$iResult-&gt;query_name();\nwhile(my$iHit=$iResult-&gt;next_hit){my$iNameH=$iHit-&gt;name();\nwhile(my$iHSP=$iHit-&gt;next_hsp){my$iStrandQ=$iHSP-&gt;strand('query');\nmy$iStrandH=$iHSP-&gt;strand('hit');\nif(($iStrandQ eq$iStrandH)and($iStrandQ ne\"\")){$iFlag=1;}else{$iFlag=0;}goto lbGotIt;}}}lbGotIt:return$iFlag;}}else{return-1;}}sub efPrintData{my(%pIdx)=@_;\nmy@pKeys=keys%pIdx;\nfor(my$pi=0;$pi&lt;@pKeys;$pi++){print\"--[$pKeys[$pi]] =&gt; [\".$pIdx{\"$pKeys[$pi]\"}.\"]---\\n\";}print\"----------------------------------------------------------------------\\n\";}sub efDNA_RC{my($qLine)=@_;\nmy@qList=split(//,$qLine);\nmy$qi=0;\nmy@qL=();\nmy$qLength=scalar@qList;\nif($qLength&gt;=1){for($qi=$qLength-1;$qi&gt;=0;$qi--){if($qList[$qi]eq\"A\"){$qL[$qLength-$qi-1]=\"T\";}elsif($qList[$qi]eq\"T\"){$qL[$qLength-$qi-1]=\"A\";}elsif($qList[$qi]eq\"G\"){$qL[$qLength-$qi-1]=\"C\";}elsif($qList[$qi]eq\"C\"){$qL[$qLength-$qi-1]=\"G\";}else{$qL[$qLength-$qi-1]=\"N\";}}$qLine=join(\"\",@qL);}else{$qLine=\"\";}return$qLine;}\n</code></pre>"},{"location":"transposon_anno_workflow/LTRRet_integration/","title":"LTR Retriever integration","text":"<p>changes made to TEUlt source code to integrate results from LTR Retriever</p>"},{"location":"transposon_anno_workflow/LTRRet_integration/#ltr-retriever-parsing-function","title":"LTR Retriever parsing function","text":"<ul> <li> add to AnnotationParsing.py</li> </ul> <pre><code># pathResDir, fastaFile, targetGFFFile, targetFastaFile\ndef parseLtrRetriever(pathResDir, fastaFile, targetGFFFile, targetFastaFile):\n    print(\"Parse ltrRetriever outputs...\")\n    transposonAnnotations = {}\n    folder = os.listdir(pathResDir)[0]\n    files  = os.listdir(os.path.join(pathResDir,folder))\n    selFile = \"\"\n    for f in files:\n        if(f.endswith(\".gff\")):\n            selFile = os.path.join(pathResDir,folder,f)\n    f = open(selFile,\"r\")\n    line = f.readline()\n    counter = 0\n    while line!=\"\":\n\n        if line.startswith(\"#\") == False:\n            transposons = line.split(\"\\t\")\n            chrom = transposons[0]\n            if(not chrom in transposonAnnotations):\n                transposonAnnotations[chrom] = list()\n\n            # print(counter)\n            annoSoftware = \"ltrRetriever\"\n            features     = \"transposon\"\n            strand = transposons[6]\n            start  = int(transposons[3])\n            end    = int(transposons[4])\n            start,end = correctPositions(start, end)\n            score  = \".\"\n            phase  = \".\"\n            transpNr = str(counter)\n            comments = transposons[8].split(\";\")\n#             print(comments)\n\n            component_id = comments[0].split('=')[1]\n\n            if(component_id[0:13] == 'repeat_region'):\n                features     = \"repeat_region\"\n                attributes = \"Repeat region of transposon \"+str(counter)\n                transposonAnnotations[chrom].append(chrom+\"\\t\"+annoSoftware+\"\\t\"+features+\"\\t\"+str(start)+\"\\t\"+str(end)+\"\\t\"+str(score)+\"\\t\"+strand+\"\\t\"+phase+\"\\t\"+transpNr+\"\\t\"+attributes)\n\n            elif(component_id[0:5] == 'LTRRT'):\n                features     = \"transposon\"\n                attributes = str(comments)\n                counter += 1\n                transposonAnnotations[chrom].append(chrom+\"\\t\"+annoSoftware+\"\\t\"+features+\"\\t\"+str(start)+\"\\t\"+str(end)+\"\\t\"+str(score)+\"\\t\"+strand+\"\\t\"+phase+\"\\t\"+transpNr+\"\\t\"+attributes)\n\n            elif(component_id[0:4] == 'lLTR'):\n                features     = \"ltr\"\n                attributes = \"Left LTR of transposon \"+str(counter)\n                transposonAnnotations[chrom].append(chrom+\"\\t\"+annoSoftware+\"\\t\"+features+\"\\t\"+str(start)+\"\\t\"+str(end)+\"\\t\"+str(score)+\"\\t\"+strand+\"\\t\"+phase+\"\\t\"+transpNr+\"\\t\"+attributes)\n\n            elif(component_id[0:4] == 'rLTR'):\n                features     = \"ltr\"\n                attributes = \"Right LTR of transposon \"+str(counter)\n                transposonAnnotations[chrom].append(chrom+\"\\t\"+annoSoftware+\"\\t\"+features+\"\\t\"+str(start)+\"\\t\"+str(end)+\"\\t\"+str(score)+\"\\t\"+strand+\"\\t\"+phase+\"\\t\"+transpNr+\"\\t\"+attributes)\n\n            elif( component_id[0:4] == 'lTSD'):\n                features     = \"tsd\"\n                attributes = \"Left TSD of transposon \"+str(counter)\n                transposonAnnotations[chrom].append(chrom+\"\\t\"+annoSoftware+\"\\t\"+features+\"\\t\"+str(start)+\"\\t\"+str(end)+\"\\t\"+str(score)+\"\\t\"+strand+\"\\t\"+phase+\"\\t\"+transpNr+\"\\t\"+attributes)\n\n            elif(component_id[0:4] == 'rTSD'):\n                features     = \"tsd\"\n                attributes = \"Right TSD of transposon \"+str(counter)\n                transposonAnnotations[chrom].append(chrom+\"\\t\"+annoSoftware+\"\\t\"+features+\"\\t\"+str(start)+\"\\t\"+str(end)+\"\\t\"+str(score)+\"\\t\"+strand+\"\\t\"+phase+\"\\t\"+transpNr+\"\\t\"+attributes)\n\n\n        line = f.readline()\n    f.close()\n\n    # Print results to Annotation file\n\n    f = open(targetGFFFile,\"w+\")\n    f.write(\"# ltrRetriever Annotation\")\n    # f.write('\\n')\n    writeGFFhead(f)\n    keys = list(transposonAnnotations.keys())\n    keys.sort()\n    for key in keys:\n        for i in range(0,len(transposonAnnotations[key])):\n            f.write(transposonAnnotations[key][i])\n            f.write(\"\\n\")\n    f.close()\n\n#     Get Transposon Sequences\n    exportFastaFile(targetFastaFile, fastaFile, keys, transposonAnnotations)\n</code></pre>"},{"location":"transposon_anno_workflow/LTRRet_integration/#ltr-retriever-check-function","title":"LTR Retriever check function","text":"<ul> <li> add to AnnotationChecker.py</li> </ul> <pre><code>def checkLtrRetriever(projectFolderPath):\n    if path.isdir(os.path.join(projectFolderPath, \"ltrRetriever\")):\n        if(getFile(os.path.join(projectFolderPath, \"ltrRetriever\"),\".gff3\")!=\"\"):\n            return True\n#        if(path.isfile(os.path.join(projectFolderPath, \"ltrHarvest\", \"result.txt\"))):\n#            return True\n    return False\n</code></pre>"},{"location":"transposon_anno_workflow/LTRRet_integration/#adding-ltr-retriever-to-lists-and-import-statements","title":"adding LTR Retriever to lists and import statements","text":"<ul> <li> append 'ltrRetriever' to list in line 94 in DuplicateFilterA.py</li> <li> append 'ltrRetriever' to list in line 58 in DuplicateFilterB.py</li> <li> append 'ltrRetriever' to validSoftwares list in line 72</li> <li> append checkLtrRetriever to import statement in line 11 in AnnotationParser.py</li> </ul>"},{"location":"transposon_anno_workflow/TEUlt_file_fxs/","title":"TEUlt file fxs","text":"<p>this is kind of dumb, but when I was troubleshooting through using TEUlt, it took me forever to figure out which specific scripts defined which steps of the pipeline, and which specific functions so here's a list lol</p>"},{"location":"transposon_anno_workflow/TEUlt_file_fxs/#annotationcheckerpy","title":"AnnotationChecker.py","text":""},{"location":"transposon_anno_workflow/TEUlt_file_fxs/#functions","title":"functions","text":""},{"location":"transposon_anno_workflow/TEUlt_file_fxs/#getargument","title":"getArgument","text":"<ul> <li>inputs<ul> <li>args</li> <li>title</li> </ul> </li> <li>outputs<ul> <li>empty string</li> </ul> </li> </ul>"},{"location":"transposon_anno_workflow/TEUlt_file_fxs/#getfile","title":"getFile","text":"<ul> <li>inputs<ul> <li>folder</li> <li>suffix</li> </ul> </li> <li>outputs<ul> <li>empty string</li> </ul> </li> </ul>"},{"location":"transposon_anno_workflow/TEUlt_file_fxs/#checkhelitronscanner","title":"checkHelitronScanner","text":"<ul> <li>inputs<ul> <li>projectFolderPath</li> </ul> </li> <li>output<ul> <li>True or False</li> </ul> </li> </ul>"},{"location":"transposon_anno_workflow/TEUlt_file_fxs/#checkltrharvest","title":"checkLtrHarvest","text":"<ul> <li>inputs<ul> <li>projectFolderPath</li> </ul> </li> <li>outputs<ul> <li>True or False</li> </ul> </li> </ul>"},{"location":"transposon_anno_workflow/TEUlt_file_fxs/#checkltrpred","title":"checkLtrPred","text":"<ul> <li>inputs<ul> <li>projectFolderPath</li> </ul> </li> <li>outputs<ul> <li>True or False</li> </ul> </li> </ul>"},{"location":"transposon_anno_workflow/TEUlt_file_fxs/#checkmitefind","title":"checkMiteFind","text":"<ul> <li>inputs<ul> <li>projectFolderPath</li> </ul> </li> <li>outputs<ul> <li>True or False</li> </ul> </li> </ul>"},{"location":"transposon_anno_workflow/TEUlt_file_fxs/#checkmitetracker","title":"checkMiteTracker","text":"<ul> <li>inputs<ul> <li>projectFolderPath</li> </ul> </li> <li>outputs<ul> <li>True or False</li> </ul> </li> </ul>"},{"location":"transposon_anno_workflow/TEUlt_file_fxs/#checkmust","title":"checkMust","text":"<ul> <li>inputs<ul> <li>projectFolderPath</li> </ul> </li> <li>outputs<ul> <li>True or False</li> </ul> </li> </ul>"},{"location":"transposon_anno_workflow/TEUlt_file_fxs/#checkncbidd1000","title":"checkNCBIDD1000","text":"<ul> <li>inputs<ul> <li>projectFolderPath</li> </ul> </li> <li>outputs<ul> <li>True or False</li> </ul> </li> </ul>"},{"location":"transposon_anno_workflow/TEUlt_file_fxs/#checkrepeatmodeler","title":"checkRepeatModeler","text":"<ul> <li>inputs<ul> <li>projectFolderPath</li> </ul> </li> <li>outputs<ul> <li>True or False</li> </ul> </li> </ul>"},{"location":"transposon_anno_workflow/TEUlt_file_fxs/#checkrepeatmasker","title":"checkRepeatMasker","text":"<ul> <li>inputs<ul> <li>projectFolderPath</li> </ul> </li> <li>outputs<ul> <li>True or False</li> </ul> </li> </ul>"},{"location":"transposon_anno_workflow/TEUlt_file_fxs/#checksinefind","title":"checkSineFind","text":"<ul> <li>inputs<ul> <li>projectFolderPath</li> </ul> </li> <li>outputs<ul> <li>True or False</li> </ul> </li> </ul>"},{"location":"transposon_anno_workflow/TEUlt_file_fxs/#checksinescan","title":"checkSineScan","text":"<ul> <li>inputs<ul> <li>projectFolderPath</li> </ul> </li> <li>outputs<ul> <li>True or False</li> </ul> </li> </ul>"},{"location":"transposon_anno_workflow/TEUlt_file_fxs/#checktirvish","title":"checkTirVish","text":"<ul> <li>inputs<ul> <li>projectFolderPath</li> </ul> </li> <li>outputs<ul> <li>True or False</li> </ul> </li> </ul>"},{"location":"transposon_anno_workflow/TEUlt_file_fxs/#checktransposonpsi","title":"checkTransposonPSI","text":"<ul> <li>inputs<ul> <li>projectFolderPath</li> </ul> </li> <li>outputs<ul> <li>True or False</li> </ul> </li> </ul>"},{"location":"transposon_anno_workflow/TEUlt_file_fxs/#checkannotations","title":"checkAnnotations","text":"<ul> <li>inputs<ul> <li>projectFolder, projectName</li> </ul> </li> <li>outputs<ul> <li>listOkay</li> </ul> </li> </ul>"},{"location":"transposon_anno_workflow/TEUlt_file_fxs/#annotationcommander","title":"AnnotationCommander","text":""},{"location":"transposon_anno_workflow/TEUlt_file_fxs/#functions_1","title":"functions","text":""},{"location":"transposon_anno_workflow/TEUlt_file_fxs/#getargument_1","title":"getArgument","text":"<ul> <li>in: args, title</li> <li>out: empty string</li> </ul>"},{"location":"transposon_anno_workflow/TEUlt_file_fxs/#runhelitronscanner","title":"runHelitronScanner","text":"<ul> <li>in: projectFolderPath</li> <li>out: runs Helitron Scanner</li> </ul>"},{"location":"transposon_anno_workflow/TEUlt_file_fxs/#runmust","title":"runMust","text":"<ul> <li>in: projectFolderPath, addCommand</li> <li>out: runs Must</li> </ul>"},{"location":"transposon_anno_workflow/TEUlt_file_fxs/#runmitetracker","title":"runMiteTracker","text":"<ul> <li>in: projectFolderPath, addCommand</li> <li>out: runs mitetracker</li> </ul>"},{"location":"transposon_anno_workflow/TEUlt_file_fxs/#runtirvish","title":"runTirVish","text":"<ul> <li>in: projectFolderPath, addCommand</li> <li>out: runs tirvish</li> </ul>"},{"location":"transposon_anno_workflow/a0_overall_anno_workflow/","title":"ANNOTATIONS","text":""},{"location":"transposon_anno_workflow/a0_overall_anno_workflow/#annotation-workflow","title":"Annotation workflow","text":"<p>These are the major steps of the transposon annotation and tracking workflow I used to generate the TE annotations. </p> <p>important</p> <p>Transposon Ultimate is referred to as TEUlt throughout this site.</p> <p>TEUlt paper</p> <p>TEUlt github</p> <ul> <li>all of the individual functions that are defined within the TEUlt are explained here -&gt; TEUlt_file_fxs (this is a work in progress)</li> <li>source code changes: <ul> <li>changes to integrate LTR Retriever -&gt; LTRRet_integration</li> <li>other random changes -&gt; other_source_changes</li> </ul> </li> </ul> <p>note</p> <p>the entire edited source code is available on the github link in the top right</p>"},{"location":"transposon_anno_workflow/a0_overall_anno_workflow/#diagram","title":"Diagram","text":"<pre><code>graph TD\n    F(1. TEUlt setup) --&gt; A;\n    F(1. TEUlt setup) --&gt; B;\n    A(2.1. TEUlt annotations) --&gt;C(Transposon Annotation);\n    B(2.2. Manual Annotations) --&gt;C(Transposon Annotation);\n    C --&gt; D(3. Combine Annotations);\n    D --&gt; E(4. Parse Annotations);\n    E --&gt; G(5. Run TEUlt Pipeline);\n    G --&gt; H(6. Annotation Stats);\n    G --&gt; I(7. Size Filtering);\n    I --&gt; J(8. Visualize);\n</code></pre>"},{"location":"transposon_anno_workflow/a0_overall_anno_workflow/#individual-steps","title":"Individual steps","text":"<ol> <li>a1_TEUlt_setup</li> <li>annotation of transposons<ol> <li>a2_1_anno_TEUlt (annotate genome using Transposon Ultimate)</li> <li>a2_2_anno_manual (annotate genome with local/manual tools)</li> </ol> </li> <li>a3_anno_combine (combine the TEUlt and local/manual transposon annotations)</li> <li>a4_anno_parse (get all TE annotations into a common file format)</li> <li>a5_anno_pipeline (run the TEUlt pipeline on all of the TE annotations</li> <li>a6_anno_stats (get stats on the non-size filtered data that was output by TEUlt)</li> <li>a7_size_filter (filter out massive TEs that were annotated but no possible way they are actual TEs)</li> <li>a8_make_pictures (make some graphs of the data and other data exploration fxns)</li> </ol>"},{"location":"transposon_anno_workflow/a0_overall_anno_workflow/#approximate-runtimes","title":"Approximate runtimes","text":"step time computer 2.1 (TEUlt annotations) ~27 hours Talapas 2.2 (manual annotations) a2_2_anno_manual#Approximate runtimes Talapas 4 (parse annotations) &lt;1 min Talapas 5 (TEUlt pipeline) ~100 min Talapas"},{"location":"transposon_anno_workflow/a1_TEUlt_setup-Cora%E2%80%99s%20MacBook%20Pro/","title":"a1 TEUlt setup Cora\u2019s MacBook Pro","text":"<p>\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000</p>"},{"location":"transposon_anno_workflow/a1_TEUlt_setup/","title":"Step 1 of overall annotation workflow","text":"<p>how to set up Transposon Ultimate yay</p>"},{"location":"transposon_anno_workflow/a1_TEUlt_setup/#transposon-ultimate-annotations","title":"Transposon Ultimate annotations","text":"<ul> <li>github link for reasonaTE</li> <li>TEUlt paper</li> </ul>"},{"location":"transposon_anno_workflow/a1_TEUlt_setup/#in-out","title":"In &amp; Out","text":"INPUT genome in fasta format OUTPUT a ton of gff3 files in a great folder organization system (except if you have to run TEUlt on multiple different genomes, all the file names will be the same which is irritating that it doesn't name the outputs based on the input fasta name but whatever, just make sure you rename your stuff if doing multiple genomes)"},{"location":"transposon_anno_workflow/a1_TEUlt_setup/#dependencies","title":"Dependencies","text":"<ul> <li>Repeat masker</li> <li>repeat modeler</li> <li>conda</li> <li>python</li> </ul>"},{"location":"transposon_anno_workflow/a1_TEUlt_setup/#install-reasonate-conda-environment-and-necessary-packages","title":"Install reasonaTE conda environment and necessary packages","text":"<ol> <li>this could take some trial and error- I didn't have any luck using mamba to install any of the conda packages, and eventually ended up using a janky combination of the .yml environment files and conda commands</li> <li>I would suggest just trying the .yml initially, rather than messing with the individual conda/mamba installations but do whatever</li> <li>in the end, you just need to end up with 2 different environments- call them what you will, but they are referred to in the reasonaTE docs as transposon_annotation_tools_env and transposon_annotation_reasonaTE so that's what I used for simplicity's sake</li> </ol>"},{"location":"transposon_anno_workflow/a1_TEUlt_setup/#create-project-workspace-on-talapas-with-input-genome","title":"Create project workspace on Talapas with input genome","text":"<ol> <li>run these commands on Talapas to load in the correct modules and make some folders that will hold everything for the transposon ultimate run on this genome <pre><code>module load python3/3.7.5\nmodule load easybuild\nmodule load anaconda3/2019.07\n\nmkdir &lt;bigfolder&gt;\ncd bigfolder/\nconda activate transposon_annotation_tools_env\nmkdir &lt;workspace&gt;\n</code></pre></li> <li> <p>replace workspace with whatever you want the overall project folder to be named</p> </li> <li> <p>upload sequence fasta file to bigfolder directory</p> <ol> <li>all chroms in the same file</li> <li>make sure that the permissions are correct for the fasta:      <pre><code>ls -l sequence.fasta\nchmod ug+rwx sequence.fasta\nchmod ug+rwx /workspace\n</code></pre></li> </ol> </li> <li> <p>run command below to create TEUlt project (this will make a duplicate of your sequence fasta file, change the chromosome names in the duplicate fasta, get folders set up for individual programs etc)  <pre><code>reasonaTE -mode createProject -projectFolder &lt;workspace&gt; -projectName &lt;testProject&gt; -inputFasta &lt;sequence.fasta&gt;\n</code></pre></p> </li> <li>replace testProject with what you want to name the project (I'd suggest including the name of the genome being analyzed or just being mildly descriptive)</li> <li>replace sequence.fasta with the name of your input genome<ul> <li>this fasta genome file must be placed within the workspace folder you made BEFORE running the reasonaTE command (the createProject reasonaTE mode renames your fasta and also creates a reverse complement version that is needed for some of the annotation tools, so the fasta has gotta be in there initially)</li> </ul> </li> </ol>"},{"location":"transposon_anno_workflow/a2_1_anno_TEUlt/","title":"Step 2.1 of overall annotation workflow","text":"<ul> <li>Step 2.2: a2_2_anno_TEUlt</li> </ul> <p>previous step:</p> <p>a1_TEUlt_setup</p> <ul> <li>transposon ultimate annotations happen in the transposon_annotation_tools_env conda environment</li> </ul>"},{"location":"transposon_anno_workflow/a2_1_anno_TEUlt/#in-out","title":"In &amp; Out","text":"INPUT genome fasta that should already be set up in the TEUlt workspace made in step 1 OUTPUT individual tool folders in TEUlt workspace populated with respective outputs of each individual annotation tool"},{"location":"transposon_anno_workflow/a2_1_anno_TEUlt/#annotate-the-genome-using-only-these-specific-transposon-ultimate-conda-packages","title":"Annotate the genome using only these specific Transposon Ultimate conda packages","text":"<ul> <li>helitronScanner</li> <li>mitefind</li> <li>mitetracker</li> <li>repeatmodel (RepeatModeler)</li> <li>repMasker (RepeatMasker)</li> <li>sinescan</li> <li>tirvish</li> <li>transposonPSI</li> <li>NCBICDD1000</li> </ul>"},{"location":"transposon_anno_workflow/a2_1_anno_TEUlt/#command-to-run-annotations","title":"Command to run annotations:","text":"<ul> <li>in theory, could run each of these tools individually and locally, using your own computer's resources but that would probably take forever, so it's better to just pop this command into a slurm script and run it from Talapas</li> <li>running all of these tools in Talapas took ~27 hours, do with that what you will</li> </ul> <pre><code>conda activate transposon_annotation_tools_env\nreasonaTE -mode annotate -projectFolder workspace -projectName testProject -tool &lt;toolname&gt;\n</code></pre>"},{"location":"transposon_anno_workflow/a2_1_anno_TEUlt/#important-notes","title":"Important notes","text":"<ul> <li>don't use the 'all' function of TEUlt in annotate mode because some of these programs didn't work and caused incomplete runs of other programs that I didn't realize were incomplete until very late</li> <li>some of the specific programs that were wrapped into conda packages for TEUlt (ie MUST v2, SINE Finder) didn't work using the conda packages, which is why I ended up running these locally and then only running specific annotation tools through the TEUlt wrapper</li> <li>run this using a Talapas job script <ul> <li>this step will take a big long time to run all of these individual tools because of Repeatmasker and Repeatmodeler, so better to just submit the job and let  it run rather than making your poor computer do it locally</li> <li>sample Talapas job script in code folder </li> </ul> </li> </ul>"},{"location":"transposon_anno_workflow/a2_2_anno_manual/","title":"Step 2.2 of overall annotation workflow","text":"<ul> <li>Step 2.1: a2_1_anno_TEUlt</li> </ul> <p>previous step:</p> <p>a1_TEUlt_setup</p> <p>IMPORTANT</p> <ul> <li>these local annotations should be run with the sequence.fasta (and sequence_rc.fasta if needed) file that was generated during the TEUlt setup process (step 1) to ensure that the chromosome naming is the same across all files</li> <li>if the chromosome naming is inconsistent, the TEUlt pipeline (step 5) will not run correctly</li> </ul>"},{"location":"transposon_anno_workflow/a2_2_anno_manual/#localmanual-annotations","title":"Local/manual annotations","text":"<ul> <li> <p> MUST</p> </li> <li> <p> LTR Finder</p> </li> <li> <p> LTR Harvest</p> </li> <li> <p> LTR Retriever</p> </li> <li> <p> SINE Finder</p> </li> </ul>"},{"location":"transposon_anno_workflow/a2_2_anno_manual/#approximate-runtimes","title":"Approximate runtimes","text":"program time computer MUST ~100 min Talapas LTR Finder parallel ~5 min Talapas LTR Harvest ~90 min local LTR Retriever ? Talapas SINE Finder ~5 min Talapas <ul> <li>LTR Harvest runtimes are really variable- runs in like 10 seconds on Libuda CB but literally took  and hour and a half for the Kim CB, and won't even run for nonTGCA motifs on Kim CB (according to the paper, the program run time is really dependent on how repetitive the genome is)</li> </ul>"},{"location":"transposon_anno_workflow/a2_2_anno_manual/#must","title":"MUST","text":"<ul> <li>MUST paper link</li> </ul> <ul> <li>MUST download link<ul> <li>yes, this looks sketchy</li> <li>it will be ok</li> <li>use cmd-F and search for MUST, download the tar.gz file titled  \"MUST.r2-4-002.Release.tar.gz\" <ul> <li>if for some reason there is a more recent version, just try to get the version above because who knows what the new one looks like</li> </ul> </li> </ul> </li> <li>this program is a hellhole of perl scripts so sorry</li> </ul>"},{"location":"transposon_anno_workflow/a2_2_anno_manual/#in-out","title":"In &amp; Out","text":"INPUT genome in fasta format OUTPUT MITE annotations (result.txt) <ul> <li>use genome file that was made during TEUlt setup (you may have to download from Talapas or copy to new directory, but DO NOT MOVE THE ORIGINAL FILE OUT OF THE TE ULT DIRECTORY)</li> <li>this is how the MUST directory needs to be structured ``` <pre><code>genome_MUST_dir\n|- MUST_talapas_script.sh\n|- MUST.r2-4-002.Release/     # unzipped MUST tar.gz \n| |- sequence.fasta\n| |- MUST_Pipe.pl\n| |- temp/\n</code></pre></li> </ul>"},{"location":"transposon_anno_workflow/a2_2_anno_manual/#dependencies","title":"Dependencies","text":"<ul> <li>NCBI BLAST version 2.2.11 (version used for publication)</li> <li>BLAT version 3.5 (version used for publication)</li> <li>\"open-3.3.0\u201d version of RepeatMasker with the revision 1.250 (version used for publication)</li> <li>languages:<ul> <li>Perl</li> <li>C/C++</li> <li>Bash</li> </ul> </li> <li>BioPerl</li> </ul>"},{"location":"transposon_anno_workflow/a2_2_anno_manual/#running-must","title":"Running MUST","text":"<ul> <li>run on Talapas, this will take a couple hours so best to not run locally</li> <li>example script for running on Talapas in code folder scripts/must_talapas.sh</li> <li>MUST is completely command line (no GUI)</li> <li>use the perl script (in scripts/MUST_Pipe.md) and run in shell using some form of the command below:</li> </ul> <pre><code>./MUST_Pipe.pl &lt;genome.fasta&gt; &lt;result.txt&gt; &lt;temp&gt; [OPTIONS]\n</code></pre> <ul> <li>need to run from directory that came from unzipping the MUST.tar.gz file where the MUST_Pipe.pl script is located</li> <li>if you name the output file result.txt when you run MUST, won't have to rename the file later for integration into TEUlt (a3_anno_combine)</li> <li>temp is the temporary directory in which intermediary files will be stored as MUST is running<ul> <li>this directory needs to be created prior to running MUST and located within directory that holds MUST_Pipe.pl script</li> </ul> </li> </ul>"},{"location":"transposon_anno_workflow/a2_2_anno_manual/#command-line-syntax","title":"command line syntax","text":"MUST CLI syntax and options (copied over from https://www.degruyter.com/document/doi/10.1515/jib-2017-0029/html?lang=en"},{"location":"transposon_anno_workflow/a2_2_anno_manual/#ltr-finder","title":"LTR Finder","text":"<ul> <li>LTR Finder paper link</li> <li>LTR Finder github</li> <li>LTR Finder parallel paper link</li> <li>LTR Finder parallel github</li> </ul>"},{"location":"transposon_anno_workflow/a2_2_anno_manual/#ltr-finder-parallel","title":"LTR Finder parallel","text":""},{"location":"transposon_anno_workflow/a2_2_anno_manual/#what-is-it","title":"What is it?","text":"<ul> <li>perl wrapper for LTR Finder</li> <li>splits chromosomes into 1Mb segments and then runs LTR Finder on all segments in parallel</li> <li>uses timeout mechanism so that complicated regions are further split if LTR Finder is taking too long on one segment</li> </ul>"},{"location":"transposon_anno_workflow/a2_2_anno_manual/#why-use-it","title":"Why use it?","text":"<ul> <li>the original LTR Finder runs sequentially, so is very slow on large genomes</li> <li>LTR Finder frequently used on plant genomes, which are large and also contain massive amounts of LTRs and transposons overall, meaning that this program took forever (1.16 years for the 14.5 Gb bread wheat genome)</li> <li>parallelization of LTR Finder resulted in up to 8500X faster identification of LTRs</li> </ul>"},{"location":"transposon_anno_workflow/a2_2_anno_manual/#in-out_1","title":"In &amp; Out","text":"INPUT genome in fasta format OUTPUT uncleaned/unfiltered LTR annotations to input into LTR Retriever <ul> <li>use genome file that was made during TEUlt setup (you may have to download from Talapas or copy to new directory, but DO NOT MOVE THE ORIGINAL FILE OUT OF THE TE ULT DIRECTORY)</li> </ul>"},{"location":"transposon_anno_workflow/a2_2_anno_manual/#running-ltr-finder-parallel","title":"Running LTR Finder parallel","text":"<ul> <li>run on Talapas</li> <li>example script for running on Talapas in code folder scripts/ltrfinder_parallel_talapas.sh</li> </ul> <pre><code>perl LTR_FINDER_parallel -harvest_out -seq sequence.fasta \n</code></pre>"},{"location":"transposon_anno_workflow/a2_2_anno_manual/#ltr-harvest","title":"LTR Harvest","text":"<p>LTR Harvest documentation</p> <ul> <li>run locally through genometools package in specific conda env<ul> <li>GenomeTools <pre><code># create conda environment\nconda create --name envname\n# add conda channels\nconda config --add channels defaults\nconda config --add channels bioconda\nconda config --add channels conda-forge\nconda config --set channel_priority strict\n# install genome tools \nconda install -n envname genometools-genometools\n</code></pre></li> </ul> </li> </ul>"},{"location":"transposon_anno_workflow/a2_2_anno_manual/#in-out_2","title":"In &amp; Out","text":"INPUT genome in fasta format OUTPUT uncleaned/unfiltered LTR annotations to input into LTR Retriever <ul> <li>use genome file that was made during TEUlt setup (you may have to download from Talapas or copy to new directory, but DO NOT MOVE THE ORIGINAL FILE OUT OF THE TE ULT DIRECTORY)</li> </ul>"},{"location":"transposon_anno_workflow/a2_2_anno_manual/#dependencies_1","title":"Dependencies","text":"<ul> <li>genometools (conda package)</li> <li>genometools documentation</li> <li>how to install genometools</li> </ul>"},{"location":"transposon_anno_workflow/a2_2_anno_manual/#running-ltr-harvest","title":"Running LTR Harvest","text":"<p>commands copied from https://github.com/oushujun/LTR_retriever#inputs 1. run gt suffixerator to create necessary indices     - Suffixerator documentation <pre><code>gt suffixerator -db sequence.fasta -indexname sequence.index -tis -suf -lcp -des -ssp -sds -dna\n</code></pre></p> <ol> <li> <p>run gt ltrharvest to get ltr annotations in format needed for LTR Retriever <pre><code>gt ltrharvest -index sequence.index -minlenltr 100 -maxlenltr 7000 -mintsd 4 -maxtsd 6 -motif TGCA -motifmis 1 -similar 85 -vic 10 -seed 20 -seqids yes -v &gt; sequence.harvest.scn\n</code></pre></p> </li> <li> <p>run gt ltrharvest to get non TGCA motif LTRs <pre><code>gt ltrharvest -index sequence.index -minlenltr 100 -maxlenltr 7000 -mintsd 4 -maxtsd 6 -similar 85 -vic 10 -seed 20 -seqids yes -v &gt; sequence.harvest.nonTGCA.scn\n</code></pre></p> </li> </ol>"},{"location":"transposon_anno_workflow/a2_2_anno_manual/#command-line-syntax_1","title":"command line syntax","text":""},{"location":"transposon_anno_workflow/a2_2_anno_manual/#ltr-retriever","title":"LTR Retriever","text":"<ul> <li>LTR Retriever paper link</li> <li>LTR Retriever download link</li> <li>conda download! very easy to follow installation directions on github</li> </ul>"},{"location":"transposon_anno_workflow/a2_2_anno_manual/#in-out_3","title":"In &amp; Out","text":"INPUT genome in fasta format, LTR RT candidates (from any combination of LTR Finder, LTRHarvest, LTR_STRUC, MGEScan 3.0.0, and LtrDetector) OUTPUT filtered and parsed LTR annotations <ul> <li>use genome file that was made during TEUlt setup (you may have to download from Talapas or copy to new directory, but DO NOT MOVE THE ORIGINAL FILE OUT OF THE TE ULT DIRECTORY)</li> </ul>"},{"location":"transposon_anno_workflow/a2_2_anno_manual/#dependencies_2","title":"Dependencies","text":"<ul> <li>TRF </li> <li>BLAST+ </li> <li>BLAST or CD-HIT</li> <li>HMMER</li> <li>RepeatMasker</li> </ul>"},{"location":"transposon_anno_workflow/a2_2_anno_manual/#getting-ltr-rt-candidates","title":"getting LTR RT candidates","text":"<ol> <li>it is sufficient to use only results from LTR Finder and LTR Harvest (pro tip: the output files from these two LTR RT candidate finders do not have to be altered for input into LTR Retriever!)</li> <li>create a new directory (calling this ltrret_dir for the rest of this) (doesn't really matter where this directory is located at this point) and copy over the following files:<ul> <li>from LTR Harvest: sequence.fa.harvest.scn and sequence.fa.harvest.nonTGCA.scn (if you decide to create/use this file for the non TGCA motif option in LTR Retriever)</li> <li>from LTR Finder: sequence.fasta.finder.combine.scn</li> <li>genome file: sequence.fasta</li> </ul> </li> <li>use command below to combine LTR Finder and LTR Harvest annotations into one file \\     <code>bash cat sequence.fa.harvest.scn sequence.fasta.finder.combine.scn &gt; sequence.fa.rawLTR.scn</code> or \\     <code>bash cat sequence.fa.harvest.scn sequence.fa.harvest.nonTGCA.scn sequence.fasta.finder.combine.scn &gt; sequence.fa.rawLTR.scn</code></li> <li>upload ltrret_dir directory to Talapas</li> <li>upload the LTR Retriever code folder to ltrret_dir (or just clone the git repo into ltrret_dir)</li> <li>use command below to run LTR Retriever <ul> <li>example script for running on Talapas in code folder (scripts/ltrret_talapas.sh)</li> <li>need to make sure that ug has rwx permissions for the LTR_Retriever executable in the LTR Retriever code folder before submitting batch job (it won't work to just give rwx to the LTR Retriever code directory, you've gotta specify the executable directly or else it gets mad and says Permission Denied) <pre><code>chmod ug+rwx ~/LTR_retriever/LTR_retriever\n</code></pre></li> </ul> </li> </ol> <pre><code>/home/calbers/libudalab/strain/LTR_retriever/LTR_retriever -genome sequence.fasta -inharvest genome.fa.rawLTR.scn -verbose -u .0000002808 &gt; sequence_LTRRetriever.out\n</code></pre>"},{"location":"transposon_anno_workflow/a2_2_anno_manual/#sine-finder","title":"SINE Finder","text":"<p>SINE Finder paper link</p> <ul> <li>the program is located in the supplemental material of the paper (the alternate download link listed (german website) doesn't work, but you can try :))</li> <li>kind of tricky to find:<ol> <li>download the supp material</li> <li>actual python script is Supp Data File 1 (txt file)</li> <li>make a copy or resave this .txt file as a .py file (change file extension) so that it will be recognized as a python script</li> </ol> </li> </ul>"},{"location":"transposon_anno_workflow/a2_2_anno_manual/#in-out_4","title":"In &amp; Out","text":"INPUT genome in fasta format (accepts .fas, .FASTA, and .mfa file extensions) OUTPUT SINE sequences in fasta format <ul> <li>use genome file that was made during TEUlt setup (you may have to download from Talapas or copy to new directory, but DO NOT MOVE THE ORIGINAL FILE OUT OF THE TE ULT DIRECTORY)</li> </ul>"},{"location":"transposon_anno_workflow/a2_2_anno_manual/#dependencies_3","title":"Dependencies","text":"<ul> <li>Python 2.7</li> </ul>"},{"location":"transposon_anno_workflow/a2_2_anno_manual/#important-notes","title":"IMPORTANT NOTES","text":"<ul> <li>NEED TO RUN CHUNK-WISE </li> <li> <p>hey, did you run this chunk-wise?</p> <ul> <li>this is why this program must be run manually- when run through the conda wrapper in Transposon Ultimate, the python recursive memory limit is exceeded for large genomes because the conda wrapper runs SINE Finder in seqwise mode, resulting in the program stopping when the memory limit is reached and subsequently incomplete annotations</li> <li>USE EXTENSION: $ -T 'chunkwise'</li> </ul> </li> <li> <p>need to run with BOTH sequence.fasta and sequence_rc.fasta because SINE finder only annotates a single strand</p> </li> <li>use genome files that were made during TEUlt setup (you may have to download from Talapas or copy to new directory, but DO NOT MOVE THE ORIGINAL FILES OUT OF THE TE ULT DIRECTORY)</li> </ul>"},{"location":"transposon_anno_workflow/a2_2_anno_manual/#running-sine-finder","title":"Running SINE Finder","text":"<ul> <li>run in Talapas</li> <li>specifically works with python2.7 (not later versions- does some whack stuff and tries to run interactively but then immediately crashes out before any arguments are passed to the prompts, (which is very possibly user error on my part, but this was just the silly way i got it to work) so long story short, have to specify v2.7)</li> </ul>"},{"location":"transposon_anno_workflow/a2_2_anno_manual/#steps","title":"Steps","text":"<ol> <li> <p>go to directory that has sequence.fasta, sequence_rc.fasta and sine_finder.py</p> <pre><code>cd sine/finder/directory\n</code></pre> </li> <li> <p>run command using python2.7</p> </li> </ol> <pre><code>python2.7 sine_finder.py -T \"chunkwise\" -V -f both sequence.fasta &gt; kim_sinefinder.out\n</code></pre>"},{"location":"transposon_anno_workflow/a2_2_anno_manual/#command-line-syntax_2","title":"command line syntax","text":"<pre><code>sine_finder [options] &lt;fastafile_name&gt;\n  OPTIONS:\n     -h     (help:) display this message.\n     -d     (description:) display a short description of the\n            program.\n     -v     (version:) print version number.\n     EVALUATION PARAMETERS:\n     -T (seqwise|chunkwise)\n            (run type:) the way how infiles are processed (default:\n            seqwise).\n            'seqwise': each sequence is loaded and searched for patterns.\n               For large sequences 'chunkwise' is the better choice.\n            'chunkwise': only fragments (chunks) of the sequence are\n               loaded and processed. The size is defined by option\n               -C. To ensure that matches do not get lost by sequence\n               splitting an overlap should be specified (option -O).\n     -t &lt;integer&gt;\n            TSD mismatch tolerance (default:2).\n     -w &lt;integer&gt;\n            word size TSD seed starts search with (default:5).\n     -p &lt;integer&gt;\n            penalty for a nucleotide mismatch in TSD search (default:\n            1).\n     -s &lt;integer&gt;\n            TSD score cutoff (default:10).\n     -o (F|R|FR)\n            direction of TSD search, allowed orientation (default:F).\n     (only chunkwise processing:)\n     -C &lt;integer&gt;\n            (chunksize:) size of each fragment loaded and processed\n            individually. Use only when -T is set to chunkwise (default:\n            100000).\n     -O &lt;integer&gt;\n            (overlap:) overlap of fragments treated by chunkwise processing.\n            Use only when -T is set to chunkwise (default:8000).\n     OTHER OPTIONS:\n     -f (fasta|csv|both)\n           (file type:) file type result is written to (default:fasta).\n     -V    (verbose:) display program call.\n</code></pre>"},{"location":"transposon_anno_workflow/a3_anno_combine/","title":"Step 3 of overall annotation workflow","text":"<p>previous step:</p> <p>a2_1_anno_TEUlt \\ a2_2_anno_manual</p> <ul> <li>at this stage, have to combine output files from any programs you ran locally into wherever you have compiled and are running TEUlt and the two conda environments</li> <li>this is pretty easy, there are just some naming conventions that have to be followed for each specific program, because the TEUlt scripts have hardcoded in some specific filenames to look for within the larger workspace folder system and it won't recognize other files as annotations to parse if they aren't named correctly</li> </ul> program file to get from outputs rename to this program info LTR Retriever ~.pass.list.gff3 just needs to end with .gff3 a2_2_anno_manual#LTR Retriever MUST the only output file result.txt a2_2_anno_manual#MUST SineFinder sequence-matches.fasta sequence-matches.fasta a2_2_anno_manual#SINE Finder"},{"location":"transposon_anno_workflow/a3_anno_combine/#check-annotation-imports","title":"Check annotation imports","text":"<p>in order to check that all of the files from programs you ran manually/locally were input into the TEUlt project folder correctly, can run annotation check command <pre><code>conda activate transposon_annotation_tools_env\nreasonaTE -mode checkAnnotations -projectFolder workspace -projectName testProject\n</code></pre> - anything that is marked as completed will be considered by the rest of the pipeline</p>"},{"location":"transposon_anno_workflow/a4_anno_parse/","title":"Step 4 of overall annotation workflow","text":"<p>previous step:</p> <p>a3_anno_combine</p> <ul> <li>need to parse annotations so that they are all in the same format and can be used in the rest of the pipeline</li> <li>annotation parsing happens in the transposon_annotation_tools_env conda environment</li> </ul>"},{"location":"transposon_anno_workflow/a4_anno_parse/#run-annotation-parsing","title":"Run annotation parsing","text":"<p><pre><code>conda activate transposon_annotation_tools_env\nreasonaTE -mode parseAnnotations -projectFolder workspace -projectName testProject\n</code></pre> - replace workspace with the name of your workspace - replace testProject with the name of your project</p>"},{"location":"transposon_anno_workflow/a4_anno_parse/#check-the-status-of-annotation-parsing","title":"Check the status of annotation parsing","text":"<p><pre><code>conda activate transposon_annotation_tools_env\nreasonaTE -mode checkParsed -projectFolder workspace -projectName testProject\n</code></pre> - replace workspace with the name of your workspace - replace testProject with the name of your project</p>"},{"location":"transposon_anno_workflow/a5_anno_pipeline/","title":"Step 5 of overall annotation workflow","text":"<p>previous step:</p> <p>a4_anno_parse</p>"},{"location":"transposon_anno_workflow/a5_anno_pipeline/#in-out","title":"In &amp; Out","text":"INPUT TE annotations from all of the individual annotation tools OUTPUT  annotations without size filtering"},{"location":"transposon_anno_workflow/a5_anno_pipeline/#run-teult-pipeline","title":"Run TEUlt Pipeline","text":"<ul> <li>now that all the annotations are in the same format, can run the TEUlt pipeline which runs the duplicate filter, CDHIT, BLASTN and then the copy filter</li> </ul> <p><pre><code>conda activate transposon_annotation_reasonaTE\nreasonaTE -mode pipeline -projectFolder workspace -projectName testProject\n</code></pre> - replace workspace with the name of your workspace - replace testProject with the name of your project</p>"},{"location":"transposon_anno_workflow/a5_anno_pipeline/#annotation-output-format","title":"Annotation output format","text":"<p>The output files are formatted according to the standard gff3 format which is documented here -&gt; gff3 format</p> column title description 1 sequence id name of the chromosome 2 source name of the program the annotation came from (for TEUlt, when all the annotations are consolidated, the individual program names are removed and all annotations are listed as sources from reasonaTE) 3 type what the annotation feature is 4 start start position of the annotation 5 stop end position of the annotation 6 score depends on the individual program annotation is from 7 strand + for forward and - for reverse 8 phase indicates the first base of the annotation that is the first base of a codon (will be a \".\" for TEUlt because codons weren't analyzed) 9 description other descriptors that were added by individual programs"},{"location":"transposon_anno_workflow/a5_anno_pipeline/#diagram-of-teult-pipeline","title":"Diagram of TEUlt pipeline","text":"<p> From Riehl et. al. TransposonUltimate </p>"},{"location":"transposon_anno_workflow/a5_anno_pipeline/#teult-family-classification-codes","title":"TEUlt family classification codes","text":"<p>These codes are used to denote the family and subfamilies of a specific transposon sequence.  From Riehl et. al. </p>"},{"location":"transposon_anno_workflow/a6_anno_stats/","title":"Step 6 of overall annotation workflow","text":"<p>previous step:</p> <p>a5_anno_pipeline</p>"},{"location":"transposon_anno_workflow/a6_anno_stats/#get-statistics-on-final-te-annotations-non-size-filtered","title":"Get statistics on final TE annotations (non size filtered)","text":"<ul> <li>this will return statistics on the NON-SIZE filtered data</li> <li>helpful for getting an overview of the data and making sure that annotations look complete across all chromosomes</li> </ul> <p><pre><code>conda activate transposon_annotation_reasonaTE\nreasonaTE -mode statistics -projectFolder workspace -projectName testProject\n</code></pre> - replace workspace with the name of your workspace - replace testProject with the name of your project</p>"},{"location":"transposon_anno_workflow/a7_size_filter/","title":"Step 7 of overall annotation workflow","text":"<p>previous step:</p> <p>a6_anno_stats</p> <ul> <li>now need to implement manual size filtering step to get rid of TEs that are outside of canonical literature ranges because programs in TEUlt will sometimes annotate HUGE portions of chromosomes as TEs</li> <li>python function (in .py file and jupyter notebook)<ul> <li>TEUlt_reasonaTE_sizefilter.py (python file)</li> <li>TEUlt_reasonaTE_sizefilter.ipynb (jupyter notebook)</li> </ul> </li> <li>this is really tricky because how do you establish parameters that do not eliminate tandem repeats or nested TEs, but also get rid of ridiculous TEs?<ul> <li>scan for tandem repeats with another program and compare to TEs eliminated using stringent parameters?</li> <li>use Tandem Repeat Finder to find tandem repeats and their overlap with annotated TEs? TRF paper</li> <li>use Red to detect de novo repeats and their overlap with annotated TEs? Red paper</li> </ul> </li> </ul>"},{"location":"transposon_anno_workflow/a7_size_filter/#in-out","title":"In &amp; out:","text":"INPUT gff3 output files from TEUlt, txt file of chromosome lengths OUTPUT new gff3 with only TEs that made it through size filtering"},{"location":"transposon_anno_workflow/a7_size_filter/#size-parameters","title":"Size parameters","text":"<p>Two sets of size parameters- stringent and non-stringent. I decided on these based on the spreadsheet attached below, which outlines the transposon classes annotated by these programs and current research on their characteristics, including their canonical sizes. transposons.xlsx</p>"},{"location":"transposon_anno_workflow/a7_size_filter/#stringent-size-parameters","title":"Stringent size parameters","text":"<ul> <li>DNA:</li> </ul> TE size (bp) Helitron 4500 CMC 2500 Zator 1800-2400 hAT 1000-2000 Sola 1- 2000-6000, 2- 4000-5000, 3- 5000-7000 Tc1/Mariner 1600 MITE 100-800 Novosib <ul> <li>Retro:</li> </ul> TE size (bp) Gypsy 9000 Copia 5000 LINEs 5000 SINEs 600 ERV 8000"},{"location":"transposon_anno_workflow/a7_size_filter/#non-stringent-size-parameters","title":"Non-stringent size parameters","text":"<ul> <li>DNA:</li> </ul> TE size (bp) Helitron 20000 CMC 20000 Zator 15000 hAT 20000 Sola 7000 Tc1/Mariner 20000 MITE 1000 Novosib 3000 <ul> <li>Retro:</li> </ul> TE size (bp) Gypsy 20000 Copia 20000 LINEs 10000 SINEs 600 ERV 8000"},{"location":"transposon_anno_workflow/a8_make_pictures/","title":"Step 8 of overall annotation workflow","text":"<p>previous step:</p> <p>a7_size_filter</p>"},{"location":"transposon_anno_workflow/a8_make_pictures/#in-out","title":"In &amp; out","text":"INPUT size filtered gff3's OUTPUT a bunch of fun graphs <p>graphing functions in jupyter notebook format:</p> <p>TEUlt_reasonaTE_graphs.ipynb</p>"},{"location":"transposon_anno_workflow/other_source_changes/","title":"source code changes","text":""},{"location":"transposon_anno_workflow/other_source_changes/#transposonclusteringpy-changes","title":"transposonclustering.py changes","text":"<p>transposonclustering.py changes to avoid this error:</p> <pre><code>Traceback (most recent call last):\n  File \"/home/calbers/.conda/envs/transposon_annotation_reasonaTE/share/TransposonAnnotator_reasonaTE/TransposonAnnotator.py\", line 160, in &lt;module&gt;\n    doTransposonClustering(os.path.join(arg1,arg2,\"transposonCandB\"),os.path.join(arg1,arg2,\"transposonCandC\"),os.path.join(arg1,arg2,\"sequence.fasta\"))\n  File \"/gpfs/home/calbers/.conda/envs/transposon_annotation_reasonaTE/share/TransposonAnnotator_reasonaTE/TransposonClustering.py\", line 187, in doTransposonClustering\n    transpIDs.append([\"transposon\"+str(cluster[0]),key]) # ERROR # append the transpIDs list with 'transposon transposon# cluster#'\nIndexError: list index out of range \n</code></pre> <p>original (lines 184-188):</p> <pre><code># Create a fasta file and save cluster sequences\ntranspIDs = list() # initialize transpIDs as blank list\nfor key in list(clusterData.keys()): # for every cluster number key in the list of clusterData keys\n    cluster = clusterData[key] # set cluster equal to the collected list value from the clusterData dict key\n    transpIDs.append([\"transposon\"+str(cluster[0]),key]) # ERROR # append the transpIDs list with 'transposon transposon# cluster#'\n</code></pre> <p>changed (lines 184-191):</p> <pre><code># Create a fasta file and save cluster sequences\ntranspIDs = list() # initialize transpIDs as blank list\nfor key in list(clusterData.keys()): # for every cluster number key in the list of clusterData keys\n      if len(clusterData[key]) != 0:\n          cluster = clusterData[key] # set cluster equal to the collected list value from the clusterData dict key\n          transpIDs.append([\"transposon\"+str(cluster[0]),key]) # ERROR # append the transpIDs list with 'transposon transposon# cluster#'\n      else:\n          pass\n</code></pre>"},{"location":"transposon_anno_workflow/prgrm_LTRFinder/","title":"LTR Finder","text":"<ul> <li>LTR Finder paper link</li> <li>LTR Finder github</li> <li>LTR Finder parallel paper link</li> <li>LTR Finder parallel github</li> </ul>"},{"location":"transposon_anno_workflow/prgrm_LTRFinder/#ltr-finder-parallel","title":"LTR Finder parallel","text":""},{"location":"transposon_anno_workflow/prgrm_LTRFinder/#what-is-it","title":"What is it?","text":"<ul> <li>perl wrapper for LTR Finder</li> <li>splits chromosomes into 1Mb segments and then runs LTR Finder on all segments in parallel</li> <li>uses timeout mechanism so that complicated regions are further split if LTR Finder is taking too long on one segment</li> </ul>"},{"location":"transposon_anno_workflow/prgrm_LTRFinder/#why-use-it","title":"Why use it?","text":"<ul> <li>the original LTR Finder runs sequentially, so is very slow on large genomes</li> <li>LTR Finder frequently used on plant genomes, which are large and also contain massive amounts of LTRs and transposons overall, meaning that this program took forever (1.16 years for the 14.5 Gb bread wheat genome)</li> <li>parallelization of LTR Finder resulted in up to 8500X faster identification of LTRs</li> </ul>"},{"location":"transposon_anno_workflow/prgrm_LTRFinder/#in-out","title":"In &amp; Out","text":"INPUT genome in fasta format OUTPUT uncleaned/unfiltered LTR annotations to input into LTR Retriever <ul> <li>use genome file that was made during TEUlt setup (you may have to download from Talapas or copy to new directory, but DO NOT MOVE THE ORIGINAL FILE OUT OF THE TE ULT DIRECTORY)</li> </ul>"},{"location":"transposon_anno_workflow/prgrm_LTRFinder/#running-ltr-finder-parallel","title":"Running LTR Finder parallel","text":"<ul> <li>run on Talapas</li> <li>example script for running on Talapas in code folder [[kim_ltrfinder_parallel_talapas.sh]]</li> </ul> <pre><code>perl LTR_FINDER_parallel -harvest_out -seq sequence.fasta \n</code></pre>"},{"location":"transposon_anno_workflow/prgrm_LTRHarvest/","title":"LTR Harvest","text":"<ul> <li>LTR Harvest documentation</li> <li>run locally through genometools package in specific conda env<ul> <li>GenomeTools <pre><code># create conda environment\nconda create --name envname\n# add conda channels\nconda config --add channels defaults\nconda config --add channels bioconda\nconda config --add channels conda-forge\nconda config --set channel_priority strict\n# install genome tools \nconda install -n envname genometools-genometools\n</code></pre></li> </ul> </li> </ul>"},{"location":"transposon_anno_workflow/prgrm_LTRHarvest/#in-out","title":"In &amp; Out","text":"INPUT genome in fasta format OUTPUT uncleaned/unfiltered LTR annotations to input into LTR Retriever <ul> <li>use genome file that was made during TEUlt setup (you may have to download from Talapas or copy to new directory, but DO NOT MOVE THE ORIGINAL FILE OUT OF THE TE ULT DIRECTORY)</li> </ul>"},{"location":"transposon_anno_workflow/prgrm_LTRHarvest/#dependencies","title":"Dependencies","text":"<ul> <li>genometools (conda package)</li> <li>genometools documentation</li> <li>how to install genometools</li> </ul>"},{"location":"transposon_anno_workflow/prgrm_LTRHarvest/#running-ltr-harvest","title":"Running LTR Harvest","text":"<p>commands copied from https://github.com/oushujun/LTR_retriever#inputs 1. run gt suffixerator to create necessary indices     - Suffixerator documentation <pre><code>gt suffixerator -db sequence.fasta -indexname sequence.index -tis -suf -lcp -des -ssp -sds -dna\n</code></pre></p> <ol> <li> <p>run gt ltrharvest to get ltr annotations in format needed for LTR Retriever <pre><code>gt ltrharvest -index sequence.index -minlenltr 100 -maxlenltr 7000 -mintsd 4 -maxtsd 6 -motif TGCA -motifmis 1 -similar 85 -vic 10 -seed 20 -seqids yes -v &gt; sequence.harvest.scn\n</code></pre></p> </li> <li> <p>run gt ltrharvest to get non TGCA motif LTRs <pre><code>gt ltrharvest -index sequence.index -minlenltr 100 -maxlenltr 7000 -mintsd 4 -maxtsd 6 -similar 85 -vic 10 -seed 20 -seqids yes -v &gt; sequence.harvest.nonTGCA.scn\n</code></pre></p> </li> </ol>"},{"location":"transposon_anno_workflow/prgrm_LTRHarvest/#command-line-syntax","title":"command line syntax","text":""},{"location":"transposon_anno_workflow/prgrm_LTRRet/","title":"LTR Retriever","text":"<ul> <li>LTR Retriever paper link</li> <li>LTR Retriever download link</li> <li>conda download! very easy to follow installation directions on github</li> </ul>"},{"location":"transposon_anno_workflow/prgrm_LTRRet/#in-out","title":"In &amp; Out","text":"INPUT genome in fasta format, LTR RT candidates (from any combination of LTR Finder, LTRHarvest, LTR_STRUC, MGEScan 3.0.0, and LtrDetector) OUTPUT filtered and parsed LTR annotations <ul> <li>use genome file that was made during TEUlt setup (you may have to download from Talapas or copy to new directory, but DO NOT MOVE THE ORIGINAL FILE OUT OF THE TE ULT DIRECTORY)</li> </ul>"},{"location":"transposon_anno_workflow/prgrm_LTRRet/#dependencies","title":"Dependencies","text":"<ul> <li>TRF </li> <li>BLAST+ </li> <li>BLAST or CD-HIT</li> <li>HMMER</li> <li>RepeatMasker</li> </ul>"},{"location":"transposon_anno_workflow/prgrm_LTRRet/#getting-ltr-rt-candidates","title":"getting LTR RT candidates","text":"<ol> <li>it is sufficient to use only results from LTR Finder and LTR Harvest (pro tip: the output files from these two LTR RT candidate finders do not have to be altered for input into LTR Retriever!)</li> <li>create a new directory (calling this ltrret_dir for the rest of this) (doesn't really matter where this directory is located at this point) and copy over the following files:<ul> <li>from LTR Harvest: sequence.fa.harvest.scn and sequence.fa.harvest.nonTGCA.scn (if you decide to create/use this file for the non TGCA motif option in LTR Retriever)</li> <li>from LTR Finder: sequence.fasta.finder.combine.scn</li> <li>genome file: sequence.fasta</li> </ul> </li> <li>use command below to combine LTR Finder and LTR Harvest annotations into one file \\     <code>bash cat sequence.fa.harvest.scn sequence.fasta.finder.combine.scn &gt; sequence.fa.rawLTR.scn</code> or \\     <code>bash cat sequence.fa.harvest.scn sequence.fa.harvest.nonTGCA.scn sequence.fasta.finder.combine.scn &gt; sequence.fa.rawLTR.scn</code></li> <li>upload ltrret_dir directory to Talapas</li> <li>upload the LTR Retriever code folder to ltrret_dir (or just clone the git repo into ltrret_dir)</li> <li>use command below to run LTR Retriever <ul> <li>example script for running on Talapas in code folder ([[kimltrret.sh]])</li> <li>need to make sure that ug has rwx permissions for the LTR_Retriever executable in the LTR Retriever code folder before submitting batch job (it won't work to just give rwx to the LTR Retriever code directory, you've gotta specify the executable directly or else it gets mad and says Permission Denied) <pre><code>chmod ug+rwx ~/LTR_retriever/LTR_retriever\n</code></pre></li> </ul> </li> </ol> <pre><code>/home/calbers/libudalab/strain/LTR_retriever/LTR_retriever -genome sequence.fasta -inharvest genome.fa.rawLTR.scn -verbose -u .0000002808 &gt; sequence_LTRRetriever.out\n</code></pre>"},{"location":"transposon_anno_workflow/prgrm_MUST/","title":"MUST","text":"<ul> <li>MUST paper link</li> <li>MUST download link<ul> <li>yes, this looks sketchy</li> <li>it will be ok</li> <li>use cmd-F and search for MUST, download the tar.gz file titled  \"MUST.r2-4-002.Release.tar.gz\" <ul> <li>if for some reason there is a more recent version, just try to get the version above because who knows what the new one looks like</li> </ul> </li> </ul> </li> <li>this program is a hellhole of perl scripts so sorry</li> </ul>"},{"location":"transposon_anno_workflow/prgrm_MUST/#in-out","title":"In &amp; Out","text":"INPUT genome in fasta format OUTPUT MITE annotations (result.txt) <ul> <li>use genome file that was made during TEUlt setup (you may have to download from Talapas or copy to new directory, but DO NOT MOVE THE ORIGINAL FILE OUT OF THE TE ULT DIRECTORY)</li> <li>this is how the MUST directory needs to be structured ``` <pre><code>genome_MUST_dir\n|- MUST_talapas_script.sh\n|- MUST.r2-4-002.Release/     # unzipped MUST tar.gz \n| |- sequence.fasta\n| |- MUST_Pipe.pl\n| |- temp/\n</code></pre></li> </ul>"},{"location":"transposon_anno_workflow/prgrm_MUST/#dependencies","title":"Dependencies","text":"<ul> <li>NCBI BLAST version 2.2.11 (version used for publication)</li> <li>BLAT version 3.5 (version used for publication)</li> <li>\"open-3.3.0\u201d version of RepeatMasker with the revision 1.250 (version used for publication)</li> <li>languages:<ul> <li>Perl</li> <li>C/C++</li> <li>Bash</li> </ul> </li> <li>BioPerl</li> </ul>"},{"location":"transposon_anno_workflow/prgrm_MUST/#running-must","title":"Running MUST","text":"<ul> <li>run on Talapas, this will take a couple hours so best to not run locally</li> <li>example script for running on Talapas in code folder [[kim_must_talapas.sh]]</li> <li>MUST is completely command line (no GUI)</li> <li>use the perl script (in MUST perl script) and run in shell using some form of the command below:</li> </ul> <pre><code>./MUST_Pipe.pl &lt;genome.fasta&gt; &lt;result.txt&gt; &lt;temp&gt; [OPTIONS]\n</code></pre> <ul> <li>need to run from directory that came from unzipping the MUST.tar.gz file where the MUST_Pipe.pl script is located</li> <li>if you name the output file result.txt when you run MUST, won't have to rename the file later for integration into TEUlt (a3_anno_combine)</li> <li>temp is the temporary directory in which intermediary files will be stored as MUST is running<ul> <li>this directory needs to be created prior to running MUST and located within directory that holds MUST_Pipe.pl script</li> </ul> </li> </ul>"},{"location":"transposon_anno_workflow/prgrm_MUST/#command-line-syntax","title":"command line syntax","text":"MUST CLI syntax and options (copied over from https://www.degruyter.com/document/doi/10.1515/jib-2017-0029/html?lang=en"},{"location":"transposon_anno_workflow/prgrm_SINEFind/","title":"SINE Finder","text":"<ul> <li>SINE Finder paper link</li> <li>the program is located in the supplemental material of the paper (the alternate download link listed (german website) doesn't work, but you can try :))</li> <li>kind of tricky to find:<ol> <li>download the supp material</li> <li>actual python script is Supp Data File 1 (txt file)</li> <li>make a copy or resave this .txt file as a .py file (change file extension) so that it will be recognized as a python script</li> </ol> </li> </ul>"},{"location":"transposon_anno_workflow/prgrm_SINEFind/#in-out","title":"In &amp; Out","text":"INPUT genome in fasta format (accepts .fas, .FASTA, and .mfa file extensions) OUTPUT SINE sequences in fasta format <ul> <li>use genome file that was made during TEUlt setup (you may have to download from Talapas or copy to new directory, but DO NOT MOVE THE ORIGINAL FILE OUT OF THE TE ULT DIRECTORY)</li> </ul>"},{"location":"transposon_anno_workflow/prgrm_SINEFind/#dependencies","title":"Dependencies","text":"<ul> <li>Python 2.7</li> </ul>"},{"location":"transposon_anno_workflow/prgrm_SINEFind/#important-notes","title":"IMPORTANT NOTES","text":"<ul> <li>NEED TO RUN CHUNK-WISE </li> <li> <p>hey, did you run this chunk-wise?</p> <ul> <li>this is why this program must be run manually- when run through the conda wrapper in Transposon Ultimate, the python recursive memory limit is exceeded for large genomes because the conda wrapper runs SINE Finder in seqwise mode, resulting in the program stopping when the memory limit is reached and subsequently incomplete annotations</li> <li>USE EXTENSION: $ -T 'chunkwise'</li> </ul> </li> <li> <p>need to run with BOTH sequence.fasta and sequence_rc.fasta because SINE finder only annotates a single strand</p> </li> <li>use genome files that were made during TEUlt setup (you may have to download from Talapas or copy to new directory, but DO NOT MOVE THE ORIGINAL FILES OUT OF THE TE ULT DIRECTORY)</li> </ul>"},{"location":"transposon_anno_workflow/prgrm_SINEFind/#running-sine-finder","title":"Running SINE Finder","text":"<ul> <li>run in Talapas</li> <li>specifically works with python2.7 (not later versions- does some whack stuff and tries to run interactively but then immediately crashes out before any arguments are passed to the prompts, (which is very possibly user error on my part, but this was just the silly way i got it to work) so long story short, have to specify v2.7)</li> </ul>"},{"location":"transposon_anno_workflow/prgrm_SINEFind/#steps","title":"Steps","text":"<ol> <li> <p>go to directory that has sequence.fasta, sequence_rc.fasta and sine_finder.py</p> <pre><code>cd sine/finder/directory\n</code></pre> </li> <li> <p>run command using python2.7</p> </li> </ol> <pre><code>python2.7 sine_finder.py -T \"chunkwise\" -V -f both sequence.fasta &gt; kim_sinefinder.out\n</code></pre>"},{"location":"transposon_anno_workflow/prgrm_SINEFind/#command-line-syntax","title":"command line syntax","text":"<pre><code>sine_finder [options] &lt;fastafile_name&gt;\n  OPTIONS:\n     -h     (help:) display this message.\n     -d     (description:) display a short description of the\n            program.\n     -v     (version:) print version number.\n     EVALUATION PARAMETERS:\n     -T (seqwise|chunkwise)\n            (run type:) the way how infiles are processed (default:\n            seqwise).\n            'seqwise': each sequence is loaded and searched for patterns.\n               For large sequences 'chunkwise' is the better choice.\n            'chunkwise': only fragments (chunks) of the sequence are\n               loaded and processed. The size is defined by option\n               -C. To ensure that matches do not get lost by sequence\n               splitting an overlap should be specified (option -O).\n     -t &lt;integer&gt;\n            TSD mismatch tolerance (default:2).\n     -w &lt;integer&gt;\n            word size TSD seed starts search with (default:5).\n     -p &lt;integer&gt;\n            penalty for a nucleotide mismatch in TSD search (default:\n            1).\n     -s &lt;integer&gt;\n            TSD score cutoff (default:10).\n     -o (F|R|FR)\n            direction of TSD search, allowed orientation (default:F).\n     (only chunkwise processing:)\n     -C &lt;integer&gt;\n            (chunksize:) size of each fragment loaded and processed\n            individually. Use only when -T is set to chunkwise (default:\n            100000).\n     -O &lt;integer&gt;\n            (overlap:) overlap of fragments treated by chunkwise processing.\n            Use only when -T is set to chunkwise (default:8000).\n     OTHER OPTIONS:\n     -f (fasta|csv|both)\n           (file type:) file type result is written to (default:fasta).\n     -V    (verbose:) display program call.\n</code></pre>"},{"location":"transposon_info/","title":"General TE info","text":"<p>Just a list of some random TE resources and info that I found and don't want to lose track of and that could maybe be helpful for some other people :)</p>"},{"location":"transposon_info/#te-info-sheet","title":"TE info sheet","text":"<p>transposons.xlsx Info I have collected about the TE families annotated by TEUlt and all of the individual programs (sources are listed and there is a page in the excel file that has the reference associated with each number)</p>"},{"location":"transposon_info/#te-links","title":"TE links","text":"<ul> <li>TE Hub: this website is so amazing, a huge wiki site full of transposon related resources</li> <li>Dfam info about DNA TEs: contains a very helpful chart including consensus sequences for termini, and the 5' and 3' ends of various TE subclasses</li> <li>Dfam TE Classification: interactive classification tree that dissects and visualizes the classification system used by Dfam for TEs</li> <li>Ten things you should know about transposable elements</li> </ul>"},{"location":"transposon_info/#papers-that-were-helpful","title":"Papers that were helpful","text":"<ul> <li>DNA Transposons and the Evolution of Eukaryotic Genomes (Feschotte and Pritham)</li> <li>Repetitive Sequences in Complex Genomes: Structure and Evolution (Jurka, Kapitonov)</li> <li>A Field Guide to Eukaryotic Transposable Elements (Wells and Feschotte)</li> <li>The outs and ins of transposition: from Mu to Kangaroo (Curcio and Derbyshire)</li> <li>The catalytic domain of all eukaryotic cut-and-paste transposase superfamilies (Yuan and Wessler)</li> <li>Rolling-circle transposons in eukaryotes (Kapitonov and Jurka)</li> <li>Repetitive-DNA elements are similarly distributed on Caenorhabditis elegans autosomes (Surzycki)</li> <li>Natural Variation in the Distribution and Abundance of Transposable Elements Across the Caenorhabditis Species (Laricchia)</li> <li>Identification of putative nonautonomous transposable elements associated with several transposon families in Caenorhabditis elegans (Oosumi)</li> <li>Exploratory analysis of transposable elements expression in the C. elegans early embryo (Ansaloni)</li> <li>Transposable elements (Hayward and Gilbert)</li> </ul>"},{"location":"transposon_mapping_workflow/m0_overall_mapping_workflow/","title":"MAPPING","text":""},{"location":"transposon_mapping_workflow/m0_overall_mapping_workflow/#mapping-workflow","title":"Mapping workflow","text":"<ul> <li>walkthrough of workflow for mapping/tracking individual transposon copies between generationally divided isolates of the same species</li> <li>most of this workflow is just concentrated within a humongous jupyter notebook that takes in all of the files and spits out a ton of info about unique TE copies (sequence, length, if/where they moved between strains, etc), files to make ideograms using RIdeogram package and other random bs</li> </ul> INPUT size filtered gff3(s), txt file of chromosome lengths, SNPs between the 2 genomes being investigated in VCF format, bedtools intersect txt file OUTPUT list of unique TE sequences and locations in both genomes being investigated, files to create ideograms using RIdeogram R package <ul> <li> need to change jupyter notebook functions to deal with chromosome names being different between input files</li> </ul> <pre><code>graph TD\n    A(determine overlap) --&gt; B(\"generate alternate sequences\")\n    B --&gt; C(search TEUlt annos for alternate seqs)</code></pre>"},{"location":"transposon_mapping_workflow/m0_overall_mapping_workflow/#dependencies","title":"Dependencies","text":"<ul> <li>bedtools</li> <li>R<ul> <li>RIdeogram (package)</li> </ul> </li> </ul>"},{"location":"transposon_mapping_workflow/m1_bedtools_intersect/","title":"Step 1 of overall mapping workflow","text":"<ul> <li>use bedtools intersect function to determine overlap of genome 1 (N2) transposons with genome 2 (CB) SNPS relative to genome 1 (N2)</li> <li>this allows for generation of unique transposon sequences that can be tracked between genomes</li> </ul>"},{"location":"transposon_mapping_workflow/m1_bedtools_intersect/#input-and-output-files","title":"Input and output files","text":"INPUT transposons.gff3 (the finaloutput from size filtered transposon ultimate data), snps vcf file OUTPUT nasty text file with overlap between transposons sequences and SNPS (transposon sequence line listed on new line with every snp that it overlaps with) <ul> <li>run in command line</li> </ul>"},{"location":"transposon_mapping_workflow/m1_bedtools_intersect/#bedtools-command","title":"Bedtools command","text":"<pre><code>bedtools intersect -wa -wb -a /FinalAnnotations_Transposons.gff3 -b SNPS.vcf\n</code></pre> option file input genome -a FinalAnnotations_Transposons.gff3 1 -b SNPS.vcf in genome 2 relative to genome 1"},{"location":"transposon_mapping_workflow/m2_jupyterparty/","title":"step 2 of overall mapping workflow","text":"<p>previous step:</p> <p>m1_bedtools_intersect</p> <ul> <li>after running bedtools intersect to get overlap between TEs and SNPs, can then plug in all files to jupyter notebook</li> </ul> <p>jupyter notebook: scripts/TEUlt_find_unique_TEs_USE_10.ipynb</p> file chromosome names SNP vcf N2_chrI, N2_chrII... (converted to Chr I, Chr II... when imported) bedtools intersect txt seq1, seq2... (converted to Chr I, Chr II... when imported) chrom lengths txt I, II... (converted to Chr I, Chr II... using fx fix_chr_names) size filtered TE gff3 seq1, seq2... (converted to Chr I, Chr II... when imported) variable to define filepath to... intersect_file text file output from bedtools intersect libN2_fasta sequence of N2 in fasta format libCB_fasta sequence of CB in fasta format vcf_file SNPs vcf N2_file size filtered N2 TE gff3 CB_file size filtered CB TE gff3 chr_lengths_file text file with lengths of all 6 chromosomes for both genomes <p>this jupyter notebook will spit out files to make the RIdeogram in the next step in R</p>"},{"location":"transposon_mapping_workflow/m3_findactuallymoved/","title":"step 3 of overall mapping workflow","text":"<p>previous step:</p> <p>m2_jupyterparty</p> <ul> <li>this step is used to determine the TEs that actually moved, versus ones that have the same position when comparing alignment coordinates</li> <li>done in jupyter notebook: scripts/TEUlt_find_unique_TEs_USE_10.ipynb</li> </ul>"},{"location":"transposon_mapping_workflow/m4_rideogram/","title":"step 4 of overall mapping workflow","text":"<p>previous step:</p> <p>m3_findactuallymoved</p> <p>link to RIdeogram documentation - used synteny command to compare locations between the two genomes</p>"},{"location":"transposon_mapping_workflow/m4_rideogram/#input-and-output","title":"input and output","text":"INPUT output tsv file from the jupyter notebook from the previous step that is specifically formatted for RIdeogram OUTPUT Ideogram plot that shows locations of unique TEs traced from N2 chroms to CB chroms"}]}